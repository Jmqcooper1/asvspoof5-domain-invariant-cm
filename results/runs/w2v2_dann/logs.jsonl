{"timestamp": "2026-02-08T11:29:57.186250Z", "level": "INFO", "logger": "__main__", "message": "Run directory: /projects/prjs1904/runs/w2v2_dann"}
{"timestamp": "2026-02-08T11:29:59.249926Z", "level": "INFO", "logger": "__main__", "message": "Git commit: 5e88564a"}
{"timestamp": "2026-02-08T11:29:59.250073Z", "level": "INFO", "logger": "__main__", "message": "Hardware: NVIDIA A100-SXM4-40GB"}
{"timestamp": "2026-02-08T11:29:59.251262Z", "level": "INFO", "logger": "__main__", "message": "CODEC classes (manifest): 12"}
{"timestamp": "2026-02-08T11:29:59.251364Z", "level": "INFO", "logger": "__main__", "message": "CODEC_Q classes (manifest): 9"}
{"timestamp": "2026-02-08T11:29:59.262968Z", "level": "INFO", "logger": "__main__", "message": "Using AUGMENTATION_CACHE_DIR from environment: /scratch-shared/jcooper/asvspoof5_augmented_cache"}
{"timestamp": "2026-02-08T11:29:59.452273Z", "level": "WARNING", "logger": "asvspoof5_domain_invariant_cm.data.codec_augment", "message": "Some requested codecs not supported by ffmpeg: {'OPUS'}. Using: ['MP3', 'AAC']"}
{"timestamp": "2026-02-08T11:29:59.452401Z", "level": "INFO", "logger": "__main__", "message": "Codec augmentor initialized: supported_codecs=['MP3', 'AAC'], codec_prob=0.5"}
{"timestamp": "2026-02-08T11:29:59.636775Z", "level": "INFO", "logger": "__main__", "message": "Train samples: 182357"}
{"timestamp": "2026-02-08T11:29:59.636926Z", "level": "INFO", "logger": "__main__", "message": "Val samples: 140950"}
{"timestamp": "2026-02-08T11:29:59.637295Z", "level": "INFO", "logger": "__main__", "message": "DANN with augmentation: domain discriminator sizes num_codecs=3, num_codec_qs=6"}
{"timestamp": "2026-02-08T11:29:59.639281Z", "level": "INFO", "logger": "__main__", "message": "Saved synthetic vocabs to run dir (DANN with augmentation)"}
{"timestamp": "2026-02-08T11:30:02.981752Z", "level": "INFO", "logger": "__main__", "message": "Total parameters: 96,344,727"}
{"timestamp": "2026-02-08T11:30:02.981911Z", "level": "INFO", "logger": "__main__", "message": "Trainable parameters: 1,973,015"}
{"timestamp": "2026-02-08T11:30:06.406830Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "Wandb initialized: https://wandb.ai/mike-cooper-uva/asvspoof5-dann/runs/giouyxnd"}
{"timestamp": "2026-02-08T11:30:06.409262Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "Model: 96,344,727 params (1,973,015 trainable)"}
{"timestamp": "2026-02-08T11:30:06.409770Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "Dataset: train=182357, val=140950"}
{"timestamp": "2026-02-08T11:30:06.410720Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[experiment_start]", "event_type": "experiment_start", "data": {"method": "dann", "backbone": "wav2vec2_base", "max_epochs": 50, "batch_size": 256, "learning_rate": 5e-05, "model": {"total_params": 96344727, "trainable_params": 1973015}, "dataset": {"train_size": 182357, "val_size": 140950}, "dann": {"lambda_init": 0.01, "lambda_schedule": {"enabled": true, "type": "exponential", "start": 0.01, "end": 1.0, "warmup_epochs": 0}}}}
{"timestamp": "2026-02-08T11:30:06.410918Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[experiment_start] method=dann, backbone=wav2vec2_base"}
{"timestamp": "2026-02-08T11:30:06.411108Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Starting training for 50 epochs"}
{"timestamp": "2026-02-08T11:30:06.411346Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Run directory: /projects/prjs1904/runs/w2v2_dann"}
{"timestamp": "2026-02-08T11:30:06.411511Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Model: 96,344,727 params (1,973,015 trainable)"}
{"timestamp": "2026-02-08T11:30:06.430865Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Dataset: train=182357, val=140950"}
{"timestamp": "2026-02-08T11:30:06.435866Z", "level": "INFO", "logger": "__main__", "message": "============================================================"}
{"timestamp": "2026-02-08T11:30:06.436116Z", "level": "INFO", "logger": "__main__", "message": "Training DANN model"}
{"timestamp": "2026-02-08T11:30:06.436307Z", "level": "INFO", "logger": "__main__", "message": "Backbone: wav2vec2_base"}
{"timestamp": "2026-02-08T11:30:06.436507Z", "level": "INFO", "logger": "__main__", "message": "Seed: 42"}
{"timestamp": "2026-02-08T11:30:06.436698Z", "level": "INFO", "logger": "__main__", "message": "============================================================"}
{"timestamp": "2026-02-08T11:30:06.436931Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 0: lambda_grl=0.010000, lambda_domain_loss=0.010000"}
{"timestamp": "2026-02-08T11:41:29.157493Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.2% (12988/25856 samples coded)"}
{"timestamp": "2026-02-08T11:52:22.608566Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.0% (25745/51456 samples coded)"}
{"timestamp": "2026-02-08T12:02:48.682090Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 49.9% (38432/77056 samples coded)"}
{"timestamp": "2026-02-08T12:14:08.511858Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.0% (51356/102656 samples coded)"}
{"timestamp": "2026-02-08T12:24:56.369084Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.0% (64126/128256 samples coded)"}
{"timestamp": "2026-02-08T12:36:12.215108Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.1% (77078/153856 samples coded)"}
{"timestamp": "2026-02-08T12:46:42.759471Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.0% (89801/179456 samples coded)"}
{"timestamp": "2026-02-08T12:47:43.620296Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 0 train: loss=0.4326, task_acc=0.8710"}
{"timestamp": "2026-02-08T12:51:19.045295Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 0 val: loss=0.4187, eer=0.2103, min_dcf=1.0000"}
{"timestamp": "2026-02-08T12:51:19.436288Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "New best eer: 0.2103"}
{"timestamp": "2026-02-08T12:51:19.437248Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 0, "duration_sec": 4873.0, "train": {"loss": 0.4326433961311083, "task_loss": 0.4050478966425309, "task_acc": 0.870994996488764, "codec_loss": 1.0571695266479857, "codec_q_loss": 1.7023804489146457, "codec_acc": 0.46075096558988765, "codec_q_acc": 0.14130530196629212, "aug_rate": 0.5003566099016854, "grad_norm_mean": 0.5462689822328445, "grad_norm_max": 1.3531641094930054, "grad_clips": 296, "nan_grads": 0}, "is_best": true, "val": {"loss": 0.4187181802388761, "task_loss": 0.4187181802388761, "task_acc": 0.7852815903466324, "eer": 0.21028114058952668, "min_dcf": 1.0}, "per_codec": {"NONE": {"eer": 0.21028114058952668, "n_samples": 140950}}, "per_codec_q": {"NONE": {"eer": 0.21028114058952668, "n_samples": 140950}}, "learning_rate": 1.78e-05, "lambda_grl": 0.01, "lambda_domain_loss": 0.01, "lambda_domain": 0.01, "layer_weights": [0.12494394928216934, 0.11597251147031784, 0.10690552741289139, 0.0984102264046669, 0.09080317616462708, 0.08372959494590759, 0.07732351869344711, 0.07132919132709503, 0.06574307382106781, 0.05952451378107071, 0.054853856563568115, 0.05046090856194496], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-08T12:51:19.437804Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=0, train_loss=0.4326, val_eer=0.2103"}
{"timestamp": "2026-02-08T12:51:19.755112Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 1: lambda_grl=0.108671, lambda_domain_loss=0.108671"}
{"timestamp": "2026-02-08T13:03:02.018023Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 49.7% (12860/25856 samples coded)"}
{"timestamp": "2026-02-08T13:14:10.525582Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 49.8% (25604/51456 samples coded)"}
{"timestamp": "2026-02-08T13:24:57.073361Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 49.8% (38350/77056 samples coded)"}
{"timestamp": "2026-02-08T13:36:02.196730Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 49.8% (51104/102656 samples coded)"}
{"timestamp": "2026-02-08T13:46:50.342670Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 49.8% (63867/128256 samples coded)"}
{"timestamp": "2026-02-08T13:58:13.220780Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 49.9% (76749/153856 samples coded)"}
{"timestamp": "2026-02-08T14:09:25.103001Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 49.9% (89573/179456 samples coded)"}
{"timestamp": "2026-02-08T14:10:41.239146Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 1 train: loss=0.3577, task_acc=0.9747"}
{"timestamp": "2026-02-08T14:14:12.942308Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 1 val: loss=0.4309, eer=0.0880, min_dcf=0.8328"}
{"timestamp": "2026-02-08T14:14:13.359955Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "New best eer: 0.0880"}
{"timestamp": "2026-02-08T14:14:13.360929Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 1, "duration_sec": 4973.61, "train": {"loss": 0.35771606150972707, "task_loss": 0.07244576852156498, "task_acc": 0.9747136148174157, "codec_loss": 1.0267537165893597, "codec_q_loss": 1.598320751879992, "codec_acc": 0.5009655898876404, "codec_q_acc": 0.12019948209269662, "aug_rate": 0.4993745610955056, "grad_norm_mean": 0.2319760939924878, "grad_norm_max": 0.6608259883077191, "grad_clips": 6, "nan_grads": 0}, "is_best": true, "val": {"loss": 0.4309354052894128, "task_loss": 0.4309354052894128, "task_acc": 0.83113033120299, "eer": 0.08799279604733672, "min_dcf": 0.8328110072820216}, "learning_rate": 3.56e-05, "lambda_grl": 0.10867131467870633, "lambda_domain_loss": 0.10867131467870633, "lambda_domain": 0.10867131467870633, "layer_weights": [0.1210884153842926, 0.11641474068164825, 0.10807259380817413, 0.09947378933429718, 0.09199635684490204, 0.08469727635383606, 0.07837432622909546, 0.07250108569860458, 0.06653786450624466, 0.058087944984436035, 0.05358435586094856, 0.049171216785907745], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-08T14:14:13.361311Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=1, train_loss=0.3577, val_eer=0.0880"}
{"timestamp": "2026-02-08T14:14:13.362503Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 2: lambda_grl=0.205402, lambda_domain_loss=0.205402"}
{"timestamp": "2026-02-08T14:26:12.193810Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 49.5% (12787/25856 samples coded)"}
{"timestamp": "2026-02-08T14:37:53.773225Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.1% (25792/51456 samples coded)"}
{"timestamp": "2026-02-08T14:48:31.743137Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 50.1% (38582/77056 samples coded)"}
{"timestamp": "2026-02-08T14:59:49.968791Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.0% (51371/102656 samples coded)"}
{"timestamp": "2026-02-08T15:10:25.799582Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.0% (64156/128256 samples coded)"}
{"timestamp": "2026-02-08T15:20:54.365052Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.0% (76925/153856 samples coded)"}
{"timestamp": "2026-02-08T15:32:08.123396Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.1% (89877/179456 samples coded)"}
{"timestamp": "2026-02-08T15:32:47.907329Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 2 train: loss=0.5168, task_acc=0.9991"}
{"timestamp": "2026-02-08T15:36:17.858024Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 2 val: loss=0.5288, eer=0.0600, min_dcf=0.5454"}
{"timestamp": "2026-02-08T15:36:18.400517Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "New best eer: 0.0600"}
{"timestamp": "2026-02-08T15:36:18.401292Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 2, "duration_sec": 4925.04, "train": {"loss": 0.5167694317407152, "task_loss": 0.006799353815561547, "task_acc": 0.999122191011236, "codec_loss": 0.9468795627020719, "codec_q_loss": 1.5359158668290362, "codec_acc": 0.5507867363061798, "codec_q_acc": 0.13721251755617977, "aug_rate": 0.5008723226825843, "grad_norm_mean": 0.23272662987334075, "grad_norm_max": 0.5768161006625562, "grad_clips": 2, "nan_grads": 0}, "is_best": true, "val": {"loss": 0.5288164289482276, "task_loss": 0.5288164289482276, "task_acc": 0.8018807660646318, "eer": 0.060004105548725255, "min_dcf": 0.5453669265666639}, "learning_rate": 4.999801925191796e-05, "lambda_grl": 0.20540156702265497, "lambda_domain_loss": 0.20540156702265497, "lambda_domain": 0.20540156702265497, "layer_weights": [0.11910850554704666, 0.11665245145559311, 0.10877130925655365, 0.10002179443836212, 0.09256968647241592, 0.08495041728019714, 0.07867123186588287, 0.07298298925161362, 0.06676454842090607, 0.05761956423521042, 0.05312564596533775, 0.04876188933849335], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-08T15:36:18.401586Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=2, train_loss=0.5168, val_eer=0.0600"}
{"timestamp": "2026-02-08T15:36:18.402830Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 3: lambda_grl=0.298399, lambda_domain_loss=0.298399"}
{"timestamp": "2026-02-08T15:47:46.827092Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.0% (12930/25856 samples coded)"}
{"timestamp": "2026-02-08T15:58:44.464598Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.0% (25731/51456 samples coded)"}
{"timestamp": "2026-02-08T16:09:42.473665Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 50.0% (38520/77056 samples coded)"}
{"timestamp": "2026-02-08T16:20:05.141823Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 49.8% (51174/102656 samples coded)"}
{"timestamp": "2026-02-08T16:31:10.148011Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 49.9% (63975/128256 samples coded)"}
{"timestamp": "2026-02-08T16:42:15.310453Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 49.9% (76845/153856 samples coded)"}
{"timestamp": "2026-02-08T16:52:51.069642Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.0% (89683/179456 samples coded)"}
{"timestamp": "2026-02-08T16:53:40.025603Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 3 train: loss=0.6935, task_acc=0.9997"}
{"timestamp": "2026-02-08T16:57:12.059931Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 3 val: loss=0.6171, eer=0.0488, min_dcf=0.4263"}
{"timestamp": "2026-02-08T16:57:12.445193Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "New best eer: 0.0488"}
{"timestamp": "2026-02-08T16:57:12.445984Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 3, "duration_sec": 4854.04, "train": {"loss": 0.6935379225551412, "task_loss": 0.0021050054636341455, "task_acc": 0.999731170997191, "codec_loss": 0.836571024291301, "codec_q_loss": 1.4805674683511927, "codec_acc": 0.6283905372191011, "codec_q_acc": 0.14453673630617977, "aug_rate": 0.4994019926264045, "grad_norm_mean": 0.4191232647410725, "grad_norm_max": 1.2427351558741428, "grad_clips": 180, "nan_grads": 0}, "is_best": true, "val": {"loss": 0.6171250408227993, "task_loss": 0.6171250408227993, "task_acc": 0.7765295107438214, "eer": 0.04876302482869995, "min_dcf": 0.4262531094697995}, "learning_rate": 4.9923030005806335e-05, "lambda_grl": 0.2983994863270749, "lambda_domain_loss": 0.2983994863270749, "lambda_domain": 0.2983994863270749, "layer_weights": [0.11456742137670517, 0.11195676773786545, 0.10682979226112366, 0.10026343911886215, 0.09491652995347977, 0.08701395988464355, 0.08054786175489426, 0.07494047284126282, 0.06840109080076218, 0.05832633748650551, 0.05336868017911911, 0.04886769875884056], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-08T16:57:12.446280Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=3, train_loss=0.6935, val_eer=0.0488"}
{"timestamp": "2026-02-08T16:57:12.447549Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 4: lambda_grl=0.386149, lambda_domain_loss=0.386149"}
{"timestamp": "2026-02-08T17:09:32.283822Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.4% (13027/25856 samples coded)"}
{"timestamp": "2026-02-08T17:20:43.457462Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.3% (25902/51456 samples coded)"}
{"timestamp": "2026-02-08T21:50:10.593560Z", "level": "INFO", "logger": "__main__", "message": "Run directory: /projects/prjs1904/runs/w2v2_dann"}
{"timestamp": "2026-02-08T21:50:12.243177Z", "level": "INFO", "logger": "__main__", "message": "Git commit: 524ce14a"}
{"timestamp": "2026-02-08T21:50:12.243334Z", "level": "INFO", "logger": "__main__", "message": "Hardware: NVIDIA A100-SXM4-40GB"}
{"timestamp": "2026-02-08T21:50:12.260394Z", "level": "INFO", "logger": "__main__", "message": "CODEC classes (manifest): 12"}
{"timestamp": "2026-02-08T21:50:12.260501Z", "level": "INFO", "logger": "__main__", "message": "CODEC_Q classes (manifest): 9"}
{"timestamp": "2026-02-08T21:50:12.287130Z", "level": "INFO", "logger": "__main__", "message": "Using AUGMENTATION_CACHE_DIR from environment: /scratch-shared/jcooper/asvspoof5_augmented_cache"}
{"timestamp": "2026-02-08T21:50:12.471218Z", "level": "WARNING", "logger": "asvspoof5_domain_invariant_cm.data.codec_augment", "message": "Some requested codecs not supported by ffmpeg: {'OPUS'}. Using: ['MP3', 'AAC']"}
{"timestamp": "2026-02-08T21:50:12.471347Z", "level": "INFO", "logger": "__main__", "message": "Codec augmentor initialized: supported_codecs=['MP3', 'AAC'], codec_prob=0.5"}
{"timestamp": "2026-02-08T21:50:13.046694Z", "level": "INFO", "logger": "__main__", "message": "Train samples: 182357"}
{"timestamp": "2026-02-08T21:50:13.046846Z", "level": "INFO", "logger": "__main__", "message": "Val samples: 140950"}
{"timestamp": "2026-02-08T21:50:13.047194Z", "level": "INFO", "logger": "__main__", "message": "DANN with augmentation: domain discriminator sizes num_codecs=3, num_codec_qs=6"}
{"timestamp": "2026-02-08T21:50:13.075244Z", "level": "INFO", "logger": "__main__", "message": "Saved synthetic vocabs to run dir (DANN with augmentation)"}
{"timestamp": "2026-02-08T21:50:16.373963Z", "level": "INFO", "logger": "__main__", "message": "Total parameters: 96,344,727"}
{"timestamp": "2026-02-08T21:50:16.374118Z", "level": "INFO", "logger": "__main__", "message": "Trainable parameters: 1,973,015"}
{"timestamp": "2026-02-08T21:50:19.799576Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "Wandb initialized: https://wandb.ai/mike-cooper-uva/asvspoof5-dann/runs/29dwp6l5"}
{"timestamp": "2026-02-08T21:50:19.802122Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "Model: 96,344,727 params (1,973,015 trainable)"}
{"timestamp": "2026-02-08T21:50:19.802625Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "Dataset: train=182357, val=140950"}
{"timestamp": "2026-02-08T21:50:19.803938Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[experiment_start]", "event_type": "experiment_start", "data": {"method": "dann", "backbone": "wav2vec2_base", "max_epochs": 50, "batch_size": 512, "learning_rate": 5e-05, "model": {"total_params": 96344727, "trainable_params": 1973015}, "dataset": {"train_size": 182357, "val_size": 140950}, "dann": {"lambda_init": 0.01, "lambda_schedule": {"enabled": true, "type": "exponential", "start": 0.01, "end": 1.0, "warmup_epochs": 0}}}}
{"timestamp": "2026-02-08T21:50:19.804127Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[experiment_start] method=dann, backbone=wav2vec2_base"}
{"timestamp": "2026-02-08T21:50:19.804322Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Starting training for 50 epochs"}
{"timestamp": "2026-02-08T21:50:19.804509Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Run directory: /projects/prjs1904/runs/w2v2_dann"}
{"timestamp": "2026-02-08T21:50:19.804690Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Model: 96,344,727 params (1,973,015 trainable)"}
{"timestamp": "2026-02-08T21:50:19.804875Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Dataset: train=182357, val=140950"}
{"timestamp": "2026-02-08T21:50:19.810200Z", "level": "INFO", "logger": "__main__", "message": "============================================================"}
{"timestamp": "2026-02-08T21:50:19.810442Z", "level": "INFO", "logger": "__main__", "message": "Training DANN model"}
{"timestamp": "2026-02-08T21:50:19.810618Z", "level": "INFO", "logger": "__main__", "message": "Backbone: wav2vec2_base"}
{"timestamp": "2026-02-08T21:50:19.810807Z", "level": "INFO", "logger": "__main__", "message": "Seed: 42"}
{"timestamp": "2026-02-08T21:50:19.810992Z", "level": "INFO", "logger": "__main__", "message": "============================================================"}
{"timestamp": "2026-02-08T21:50:19.811221Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 0: lambda_grl=0.010000, lambda_domain_loss=0.010000"}
{"timestamp": "2026-02-08T22:05:53.695753Z", "level": "INFO", "logger": "__main__", "message": "Run directory: /projects/prjs1904/runs/w2v2_dann"}
{"timestamp": "2026-02-08T22:05:54.832240Z", "level": "INFO", "logger": "__main__", "message": "Git commit: 65bf061a"}
{"timestamp": "2026-02-08T22:05:54.832387Z", "level": "INFO", "logger": "__main__", "message": "Hardware: NVIDIA A100-SXM4-40GB"}
{"timestamp": "2026-02-08T22:05:54.833072Z", "level": "INFO", "logger": "__main__", "message": "CODEC classes (manifest): 12"}
{"timestamp": "2026-02-08T22:05:54.833173Z", "level": "INFO", "logger": "__main__", "message": "CODEC_Q classes (manifest): 9"}
{"timestamp": "2026-02-08T22:05:54.833349Z", "level": "INFO", "logger": "__main__", "message": "Using AUGMENTATION_CACHE_DIR from environment: /scratch-shared/jcooper/asvspoof5_augmented_cache"}
{"timestamp": "2026-02-08T22:05:55.013271Z", "level": "WARNING", "logger": "asvspoof5_domain_invariant_cm.data.codec_augment", "message": "Some requested codecs not supported by ffmpeg: {'OPUS'}. Using: ['MP3', 'AAC']"}
{"timestamp": "2026-02-08T22:05:55.013385Z", "level": "INFO", "logger": "__main__", "message": "Codec augmentor initialized: supported_codecs=['MP3', 'AAC'], codec_prob=0.5"}
{"timestamp": "2026-02-08T22:05:55.275441Z", "level": "INFO", "logger": "__main__", "message": "Train samples: 182357"}
{"timestamp": "2026-02-08T22:05:55.275590Z", "level": "INFO", "logger": "__main__", "message": "Val samples: 140950"}
{"timestamp": "2026-02-08T22:05:55.275937Z", "level": "INFO", "logger": "__main__", "message": "DANN with augmentation: domain discriminator sizes num_codecs=3, num_codec_qs=6"}
{"timestamp": "2026-02-08T22:05:55.277474Z", "level": "INFO", "logger": "__main__", "message": "Saved synthetic vocabs to run dir (DANN with augmentation)"}
{"timestamp": "2026-02-08T22:05:57.686766Z", "level": "INFO", "logger": "__main__", "message": "Total parameters: 96,344,727"}
{"timestamp": "2026-02-08T22:05:57.686975Z", "level": "INFO", "logger": "__main__", "message": "Trainable parameters: 1,973,015"}
{"timestamp": "2026-02-08T22:05:59.330932Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "Wandb initialized: https://wandb.ai/mike-cooper-uva/asvspoof5-dann/runs/3cbrmrdz"}
{"timestamp": "2026-02-08T22:05:59.333543Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "Model: 96,344,727 params (1,973,015 trainable)"}
{"timestamp": "2026-02-08T22:05:59.334181Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "Dataset: train=182357, val=140950"}
{"timestamp": "2026-02-08T22:05:59.335108Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[experiment_start]", "event_type": "experiment_start", "data": {"method": "dann", "backbone": "wav2vec2_base", "max_epochs": 50, "batch_size": 256, "learning_rate": 5e-05, "model": {"total_params": 96344727, "trainable_params": 1973015}, "dataset": {"train_size": 182357, "val_size": 140950}, "dann": {"lambda_init": 0.01, "lambda_schedule": {"enabled": true, "type": "exponential", "start": 0.01, "end": 1.0, "warmup_epochs": 0}}}}
{"timestamp": "2026-02-08T22:05:59.335350Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[experiment_start] method=dann, backbone=wav2vec2_base"}
{"timestamp": "2026-02-08T22:05:59.335880Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Starting training for 50 epochs"}
{"timestamp": "2026-02-08T22:05:59.336051Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Run directory: /projects/prjs1904/runs/w2v2_dann"}
{"timestamp": "2026-02-08T22:05:59.336290Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Model: 96,344,727 params (1,973,015 trainable)"}
{"timestamp": "2026-02-08T22:05:59.336499Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Dataset: train=182357, val=140950"}
{"timestamp": "2026-02-08T22:05:59.341430Z", "level": "INFO", "logger": "__main__", "message": "============================================================"}
{"timestamp": "2026-02-08T22:05:59.341626Z", "level": "INFO", "logger": "__main__", "message": "Training DANN model"}
{"timestamp": "2026-02-08T22:05:59.341781Z", "level": "INFO", "logger": "__main__", "message": "Backbone: wav2vec2_base"}
{"timestamp": "2026-02-08T22:05:59.341978Z", "level": "INFO", "logger": "__main__", "message": "Seed: 42"}
{"timestamp": "2026-02-08T22:05:59.342125Z", "level": "INFO", "logger": "__main__", "message": "============================================================"}
{"timestamp": "2026-02-08T22:05:59.342338Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 0: lambda_grl=0.010000, lambda_domain_loss=0.010000"}
{"timestamp": "2026-02-08T22:17:13.084451Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.2% (12988/25856 samples coded)"}
{"timestamp": "2026-02-08T22:28:11.348881Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.0% (25745/51456 samples coded)"}
{"timestamp": "2026-02-08T22:38:24.812948Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 49.9% (38432/77056 samples coded)"}
{"timestamp": "2026-02-08T22:49:56.298907Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.0% (51356/102656 samples coded)"}
{"timestamp": "2026-02-08T23:00:29.639213Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.0% (64126/128256 samples coded)"}
{"timestamp": "2026-02-08T23:11:38.166115Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.1% (77078/153856 samples coded)"}
{"timestamp": "2026-02-08T23:21:43.897886Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.0% (89801/179456 samples coded)"}
{"timestamp": "2026-02-08T23:22:45.679983Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 0 train: loss=0.4326, task_acc=0.8710"}
{"timestamp": "2026-02-08T23:26:21.813148Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 0 val: loss=0.4187, eer=0.2103, min_dcf=1.0000"}
{"timestamp": "2026-02-08T23:26:22.637853Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "New best eer: 0.2103"}
{"timestamp": "2026-02-08T23:26:22.638765Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 0, "duration_sec": 4823.3, "train": {"loss": 0.4326433961311083, "task_loss": 0.4050478966425309, "task_acc": 0.870994996488764, "codec_loss": 1.0571695266479857, "codec_q_loss": 1.7023804489146457, "codec_acc": 0.46075096558988765, "codec_q_acc": 0.14130530196629212, "aug_rate": 0.5003566099016854, "grad_norm_mean": 0.5462689822328445, "grad_norm_max": 1.3531641094930054, "grad_clips": 296, "nan_grads": 0}, "is_best": true, "val": {"loss": 0.4187181802388761, "task_loss": 0.4187181802388761, "task_acc": 0.7852815903466324, "eer": 0.21028114058952668, "min_dcf": 1.0}, "per_codec": {"NONE": {"eer": 0.21028114058952668, "n_samples": 140950}}, "per_codec_q": {"NONE": {"eer": 0.21028114058952668, "n_samples": 140950}}, "learning_rate": 1.78e-05, "lambda_grl": 0.01, "lambda_domain_loss": 0.01, "lambda_domain": 0.01, "layer_weights": [0.12494394928216934, 0.11597251147031784, 0.10690552741289139, 0.0984102264046669, 0.09080317616462708, 0.08372959494590759, 0.07732351869344711, 0.07132919132709503, 0.06574307382106781, 0.05952451378107071, 0.054853856563568115, 0.05046090856194496], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-08T23:26:22.691013Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=0, train_loss=0.4326, val_eer=0.2103"}
{"timestamp": "2026-02-08T23:26:23.064569Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 1: lambda_grl=0.108671, lambda_domain_loss=0.108671"}
{"timestamp": "2026-02-08T23:37:47.966116Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 49.7% (12860/25856 samples coded)"}
{"timestamp": "2026-02-08T23:48:36.626408Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 49.8% (25604/51456 samples coded)"}
{"timestamp": "2026-02-08T23:59:21.785157Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 49.8% (38350/77056 samples coded)"}
{"timestamp": "2026-02-09T00:10:24.284174Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 49.8% (51104/102656 samples coded)"}
{"timestamp": "2026-02-09T00:20:56.153543Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 49.8% (63867/128256 samples coded)"}
{"timestamp": "2026-02-09T00:31:39.091365Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 49.9% (76749/153856 samples coded)"}
{"timestamp": "2026-02-09T00:42:41.448513Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 49.9% (89573/179456 samples coded)"}
{"timestamp": "2026-02-09T00:43:40.341307Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 1 train: loss=0.3577, task_acc=0.9747"}
{"timestamp": "2026-02-09T00:47:12.217386Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 1 val: loss=0.4309, eer=0.0880, min_dcf=0.8328"}
{"timestamp": "2026-02-09T00:47:12.616036Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "New best eer: 0.0880"}
{"timestamp": "2026-02-09T00:47:12.616880Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 1, "duration_sec": 4849.55, "train": {"loss": 0.35771606150972707, "task_loss": 0.07244576852156498, "task_acc": 0.9747136148174157, "codec_loss": 1.0267537165893597, "codec_q_loss": 1.598320751879992, "codec_acc": 0.5009655898876404, "codec_q_acc": 0.12019948209269662, "aug_rate": 0.4993745610955056, "grad_norm_mean": 0.2319760939924878, "grad_norm_max": 0.6608259883077191, "grad_clips": 6, "nan_grads": 0}, "is_best": true, "val": {"loss": 0.4309354052894128, "task_loss": 0.4309354052894128, "task_acc": 0.83113033120299, "eer": 0.08799279604733672, "min_dcf": 0.8328110072820216}, "learning_rate": 3.56e-05, "lambda_grl": 0.10867131467870633, "lambda_domain_loss": 0.10867131467870633, "lambda_domain": 0.10867131467870633, "layer_weights": [0.1210884153842926, 0.11641474068164825, 0.10807259380817413, 0.09947378933429718, 0.09199635684490204, 0.08469727635383606, 0.07837432622909546, 0.07250108569860458, 0.06653786450624466, 0.058087944984436035, 0.05358435586094856, 0.049171216785907745], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T00:47:12.617167Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=1, train_loss=0.3577, val_eer=0.0880"}
{"timestamp": "2026-02-09T00:47:12.618438Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 2: lambda_grl=0.205402, lambda_domain_loss=0.205402"}
{"timestamp": "2026-02-09T00:58:33.292075Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 49.5% (12787/25856 samples coded)"}
{"timestamp": "2026-02-09T01:09:37.552711Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.1% (25792/51456 samples coded)"}
{"timestamp": "2026-02-09T01:20:04.262613Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 50.1% (38582/77056 samples coded)"}
{"timestamp": "2026-02-09T01:31:02.273126Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.0% (51371/102656 samples coded)"}
{"timestamp": "2026-02-09T01:41:38.166996Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.0% (64156/128256 samples coded)"}
{"timestamp": "2026-02-09T01:51:59.695184Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.0% (76925/153856 samples coded)"}
{"timestamp": "2026-02-09T02:03:04.154506Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.1% (89877/179456 samples coded)"}
{"timestamp": "2026-02-09T02:03:44.925239Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 2 train: loss=0.5168, task_acc=0.9991"}
{"timestamp": "2026-02-09T02:07:16.996108Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 2 val: loss=0.5288, eer=0.0600, min_dcf=0.5454"}
{"timestamp": "2026-02-09T02:07:17.431182Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "New best eer: 0.0600"}
{"timestamp": "2026-02-09T02:07:17.432032Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 2, "duration_sec": 4804.81, "train": {"loss": 0.5167694317407152, "task_loss": 0.006799353815561547, "task_acc": 0.999122191011236, "codec_loss": 0.9468795627020719, "codec_q_loss": 1.5359158668290362, "codec_acc": 0.5507867363061798, "codec_q_acc": 0.13721251755617977, "aug_rate": 0.5008723226825843, "grad_norm_mean": 0.23272662987334075, "grad_norm_max": 0.5768161006625562, "grad_clips": 2, "nan_grads": 0}, "is_best": true, "val": {"loss": 0.5288164289482276, "task_loss": 0.5288164289482276, "task_acc": 0.8018807660646318, "eer": 0.060004105548725255, "min_dcf": 0.5453669265666639}, "learning_rate": 4.999801925191796e-05, "lambda_grl": 0.20540156702265497, "lambda_domain_loss": 0.20540156702265497, "lambda_domain": 0.20540156702265497, "layer_weights": [0.11910850554704666, 0.11665245145559311, 0.10877130925655365, 0.10002179443836212, 0.09256968647241592, 0.08495041728019714, 0.07867123186588287, 0.07298298925161362, 0.06676454842090607, 0.05761956423521042, 0.05312564596533775, 0.04876188933849335], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T02:07:17.432403Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=2, train_loss=0.5168, val_eer=0.0600"}
{"timestamp": "2026-02-09T02:07:17.433667Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 3: lambda_grl=0.298399, lambda_domain_loss=0.298399"}
{"timestamp": "2026-02-09T02:19:26.326690Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.0% (12930/25856 samples coded)"}
{"timestamp": "2026-02-09T02:30:57.043327Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.0% (25731/51456 samples coded)"}
{"timestamp": "2026-02-09T02:42:19.638324Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 50.0% (38520/77056 samples coded)"}
{"timestamp": "2026-02-09T02:53:27.615705Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 49.8% (51174/102656 samples coded)"}
{"timestamp": "2026-02-09T03:04:52.191894Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 49.9% (63975/128256 samples coded)"}
{"timestamp": "2026-02-09T03:16:31.919501Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 49.9% (76845/153856 samples coded)"}
{"timestamp": "2026-02-09T03:27:27.636386Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.0% (89683/179456 samples coded)"}
{"timestamp": "2026-02-09T03:28:18.861887Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 3 train: loss=0.6935, task_acc=0.9997"}
{"timestamp": "2026-02-09T03:31:50.963869Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 3 val: loss=0.6171, eer=0.0488, min_dcf=0.4263"}
{"timestamp": "2026-02-09T03:31:51.375864Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "New best eer: 0.0488"}
{"timestamp": "2026-02-09T03:31:51.376712Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 3, "duration_sec": 5073.94, "train": {"loss": 0.6935379225551412, "task_loss": 0.0021050054636341455, "task_acc": 0.999731170997191, "codec_loss": 0.836571024291301, "codec_q_loss": 1.4805674683511927, "codec_acc": 0.6283905372191011, "codec_q_acc": 0.14453673630617977, "aug_rate": 0.4994019926264045, "grad_norm_mean": 0.4191232647410725, "grad_norm_max": 1.2427351558741428, "grad_clips": 180, "nan_grads": 0}, "is_best": true, "val": {"loss": 0.6171250408227993, "task_loss": 0.6171250408227993, "task_acc": 0.7765295107438214, "eer": 0.04876302482869995, "min_dcf": 0.4262531094697995}, "learning_rate": 4.9923030005806335e-05, "lambda_grl": 0.2983994863270749, "lambda_domain_loss": 0.2983994863270749, "lambda_domain": 0.2983994863270749, "layer_weights": [0.11456742137670517, 0.11195676773786545, 0.10682979226112366, 0.10026343911886215, 0.09491652995347977, 0.08701395988464355, 0.08054786175489426, 0.07494047284126282, 0.06840109080076218, 0.05832633748650551, 0.05336868017911911, 0.04886769875884056], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T03:31:51.376994Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=3, train_loss=0.6935, val_eer=0.0488"}
{"timestamp": "2026-02-09T03:31:51.378260Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 4: lambda_grl=0.386149, lambda_domain_loss=0.386149"}
{"timestamp": "2026-02-09T03:43:54.198028Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.4% (13027/25856 samples coded)"}
{"timestamp": "2026-02-09T03:55:14.048368Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.3% (25902/51456 samples coded)"}
{"timestamp": "2026-02-09T04:06:18.164497Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 50.2% (38648/77056 samples coded)"}
{"timestamp": "2026-02-09T04:17:31.696990Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.2% (51529/102656 samples coded)"}
{"timestamp": "2026-02-09T04:29:08.462967Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.2% (64401/128256 samples coded)"}
{"timestamp": "2026-02-09T04:40:09.006732Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.3% (77392/153856 samples coded)"}
{"timestamp": "2026-02-09T04:51:17.279115Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.2% (90093/179456 samples coded)"}
{"timestamp": "2026-02-09T04:52:11.931276Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 4 train: loss=0.8615, task_acc=0.9998"}
{"timestamp": "2026-02-09T04:55:44.179406Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 4 val: loss=0.6880, eer=0.0455, min_dcf=0.3976"}
{"timestamp": "2026-02-09T04:55:44.595144Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "New best eer: 0.0455"}
{"timestamp": "2026-02-09T04:55:44.596039Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 4, "duration_sec": 5033.22, "train": {"loss": 0.8615015706654345, "task_loss": 0.0011725594547570336, "task_acc": 0.999829924508427, "codec_loss": 0.7773589792378833, "codec_q_loss": 1.4506099483605182, "codec_acc": 0.6549113412921348, "codec_q_acc": 0.14736218398876405, "aug_rate": 0.5020463922050562, "grad_norm_mean": 0.7173132718558077, "grad_norm_max": 2.1432691779771855, "grad_clips": 506, "nan_grads": 0}, "is_best": true, "val": {"loss": 0.6879511884466057, "task_loss": 0.6879511884466057, "task_acc": 0.7650113430300123, "eer": 0.045541190592779585, "min_dcf": 0.3976427398767352}, "learning_rate": 4.97398424882994e-05, "lambda_grl": 0.38614947263267274, "lambda_domain_loss": 0.38614947263267274, "lambda_domain": 0.38614947263267274, "layer_weights": [0.10929468274116516, 0.10677686333656311, 0.1029277816414833, 0.09995805472135544, 0.09800676256418228, 0.089899443089962, 0.08329914510250092, 0.07775265723466873, 0.07058697193861008, 0.05904639884829521, 0.05362176522612572, 0.04882938042283058], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T04:55:44.596337Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=4, train_loss=0.8615, val_eer=0.0455"}
{"timestamp": "2026-02-09T04:55:44.597716Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 5: lambda_grl=0.467496, lambda_domain_loss=0.467496"}
{"timestamp": "2026-02-09T05:07:47.038245Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.3% (13001/25856 samples coded)"}
{"timestamp": "2026-02-09T05:19:25.291988Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.1% (25795/51456 samples coded)"}
{"timestamp": "2026-02-09T05:29:58.207533Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 50.1% (38591/77056 samples coded)"}
{"timestamp": "2026-02-09T05:41:27.613818Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 49.9% (51231/102656 samples coded)"}
{"timestamp": "2026-02-09T05:51:56.689097Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 49.9% (64031/128256 samples coded)"}
{"timestamp": "2026-02-09T06:03:42.817141Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 49.9% (76788/153856 samples coded)"}
{"timestamp": "2026-02-09T06:14:24.639398Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 49.9% (89633/179456 samples coded)"}
{"timestamp": "2026-02-09T06:15:34.903382Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 5 train: loss=1.0183, task_acc=0.9999"}
{"timestamp": "2026-02-09T06:19:06.947554Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 5 val: loss=0.7740, eer=0.0460, min_dcf=0.3963"}
{"timestamp": "2026-02-09T06:19:06.966327Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 5, "duration_sec": 5002.37, "train": {"loss": 1.018281756659572, "task_loss": 0.0008207784165207476, "task_acc": 0.9998957601825843, "codec_loss": 0.7428664503137717, "codec_q_loss": 1.4335393982656885, "codec_acc": 0.6699767380617978, "codec_q_acc": 0.15022054950842698, "aug_rate": 0.4996653353230337, "grad_norm_mean": 0.9794739709848337, "grad_norm_max": 2.8357345269337215, "grad_clips": 671, "nan_grads": 0}, "is_best": false, "val": {"loss": 0.773974563270645, "task_loss": 0.773974563270645, "task_acc": 0.7508133885648419, "eer": 0.04595389499316889, "min_dcf": 0.39631053977674313}, "per_codec": {"NONE": {"eer": 0.04595389499316889, "n_samples": 140950}}, "per_codec_q": {"NONE": {"eer": 0.04595389499316889, "n_samples": 140950}}, "learning_rate": 4.9449268251965814e-05, "lambda_grl": 0.4674959856874097, "lambda_domain_loss": 0.4674959856874097, "lambda_domain": 0.4674959856874097, "layer_weights": [0.1045425683259964, 0.1022634506225586, 0.09900695085525513, 0.09925320744514465, 0.100931316614151, 0.09273277968168259, 0.0861530750989914, 0.08059366792440414, 0.07262477278709412, 0.059508226811885834, 0.05375002324581146, 0.0486399382352829], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T06:19:06.966605Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=5, train_loss=1.0183, val_eer=0.0460"}
{"timestamp": "2026-02-09T06:19:07.392014Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 6: lambda_grl=0.541679, lambda_domain_loss=0.541679"}
{"timestamp": "2026-02-09T06:31:14.114431Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.2% (12992/25856 samples coded)"}
{"timestamp": "2026-02-09T06:42:12.435312Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.2% (25814/51456 samples coded)"}
{"timestamp": "2026-02-09T06:53:43.002555Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 50.1% (38624/77056 samples coded)"}
{"timestamp": "2026-02-09T07:04:35.129969Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.1% (51474/102656 samples coded)"}
{"timestamp": "2026-02-09T07:16:01.357798Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.1% (64230/128256 samples coded)"}
{"timestamp": "2026-02-09T07:27:10.465740Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.1% (77142/153856 samples coded)"}
{"timestamp": "2026-02-09T07:38:13.800827Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.1% (89987/179456 samples coded)"}
{"timestamp": "2026-02-09T07:39:03.118615Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 6 train: loss=1.1654, task_acc=0.9999"}
{"timestamp": "2026-02-09T07:42:35.045379Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 6 val: loss=0.7954, eer=0.0453, min_dcf=0.3859"}
{"timestamp": "2026-02-09T07:42:35.059295Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 6, "duration_sec": 5007.67, "train": {"loss": 1.165389646472556, "task_loss": 0.0005930699640588643, "task_acc": 0.9999122191011236, "codec_loss": 0.72433422514227, "codec_q_loss": 1.4260101639822629, "codec_acc": 0.675561797752809, "codec_q_acc": 0.1505661867977528, "aug_rate": 0.5015690835674157, "grad_norm_mean": 1.2601253608535785, "grad_norm_max": 3.6056620186942756, "grad_clips": 712, "nan_grads": 0}, "is_best": false, "val": {"loss": 0.7954321883334872, "task_loss": 0.7954321883334872, "task_acc": 0.7530749017227367, "eer": 0.045320017772085594, "min_dcf": 0.38590297538863905}, "learning_rate": 4.90525945912189e-05, "lambda_grl": 0.5416790713280547, "lambda_domain_loss": 0.5416790713280547, "lambda_domain": 0.5416790713280547, "layer_weights": [0.10028798133134842, 0.09830565005540848, 0.09540539979934692, 0.09840171039104462, 0.1036132350564003, 0.0953865796327591, 0.08892548829317093, 0.08323048055171967, 0.0744897723197937, 0.05978383123874664, 0.0537581667304039, 0.04841168224811554], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T07:42:35.060129Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=6, train_loss=1.1654, val_eer=0.0453"}
{"timestamp": "2026-02-09T07:42:35.061442Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 7: lambda_grl=0.608324, lambda_domain_loss=0.608324"}
{"timestamp": "2026-02-09T07:54:33.567525Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.3% (13006/25856 samples coded)"}
{"timestamp": "2026-02-09T08:06:02.025601Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.2% (25824/51456 samples coded)"}
{"timestamp": "2026-02-09T08:17:03.475351Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 50.3% (38741/77056 samples coded)"}
{"timestamp": "2026-02-09T08:28:38.241632Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.1% (51463/102656 samples coded)"}
{"timestamp": "2026-02-09T08:39:43.638830Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.0% (64190/128256 samples coded)"}
{"timestamp": "2026-02-09T08:51:14.516980Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.0% (76912/153856 samples coded)"}
{"timestamp": "2026-02-09T09:02:23.838427Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.0% (89732/179456 samples coded)"}
{"timestamp": "2026-02-09T09:03:39.390936Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 7 train: loss=1.2951, task_acc=0.9999"}
{"timestamp": "2026-02-09T09:07:11.821671Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 7 val: loss=0.5947, eer=0.0452, min_dcf=0.3779"}
{"timestamp": "2026-02-09T09:07:11.836698Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 7, "duration_sec": 5076.77, "train": {"loss": 1.2950579018405315, "task_loss": 0.0005660751964845413, "task_acc": 0.9999067327949438, "codec_loss": 0.7074506073520425, "codec_q_loss": 1.4205134217993598, "codec_acc": 0.6834675649578652, "codec_q_acc": 0.15287043539325842, "aug_rate": 0.5000548630617978, "grad_norm_mean": 1.6180049971404626, "grad_norm_max": 5.231377603001893, "grad_clips": 712, "nan_grads": 0}, "is_best": false, "val": {"loss": 0.5947270770903724, "task_loss": 0.5947270770903724, "task_acc": 0.8099655928715603, "eer": 0.04519233005228872, "min_dcf": 0.377872009130102}, "learning_rate": 4.855157883937853e-05, "lambda_grl": 0.608324099345992, "lambda_domain_loss": 0.608324099345992, "lambda_domain": 0.608324099345992, "layer_weights": [0.09650454670190811, 0.09482569992542267, 0.09223601222038269, 0.0974169448018074, 0.10608919709920883, 0.0978337898850441, 0.09151902794837952, 0.0857078954577446, 0.07611607015132904, 0.05991359427571297, 0.05369972437620163, 0.048137515783309937], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T09:07:11.837097Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=7, train_loss=1.2951, val_eer=0.0452"}
{"timestamp": "2026-02-09T09:07:11.838367Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 8: lambda_grl=0.667396, lambda_domain_loss=0.667396"}
{"timestamp": "2026-02-09T09:19:14.192850Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 49.8% (12888/25856 samples coded)"}
{"timestamp": "2026-02-09T09:31:12.605229Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.0% (25733/51456 samples coded)"}
{"timestamp": "2026-02-09T09:42:15.592336Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 50.0% (38556/77056 samples coded)"}
{"timestamp": "2026-02-09T09:56:11.026510Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.1% (51412/102656 samples coded)"}
{"timestamp": "2026-02-09T10:07:45.093490Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.1% (64233/128256 samples coded)"}
{"timestamp": "2026-02-09T10:18:59.476119Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.0% (76994/153856 samples coded)"}
{"timestamp": "2026-02-09T10:29:57.213398Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.2% (90014/179456 samples coded)"}
{"timestamp": "2026-02-09T10:30:47.116345Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 8 train: loss=1.4102, task_acc=0.9999"}
{"timestamp": "2026-02-09T10:34:19.473105Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 8 val: loss=1.0140, eer=0.0468, min_dcf=0.3945"}
{"timestamp": "2026-02-09T10:34:19.495217Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 8, "duration_sec": 5227.66, "train": {"loss": 1.4102099085791726, "task_loss": 0.000443695482440336, "task_acc": 0.9999231917134831, "codec_loss": 0.69768278392848, "codec_q_loss": 1.4146542954310943, "codec_acc": 0.6862381495786517, "codec_q_acc": 0.15347941537921347, "aug_rate": 0.5016623507724719, "grad_norm_mean": 1.9976304244025564, "grad_norm_max": 7.534932981107808, "grad_clips": 712, "nan_grads": 0}, "is_best": false, "val": {"loss": 1.0140398007339229, "task_loss": 1.0140398007339229, "task_acc": 0.7207769019201317, "eer": 0.046779303793947485, "min_dcf": 0.3944744371240455}, "learning_rate": 4.794844058337874e-05, "lambda_grl": 0.6673964025651704, "lambda_domain_loss": 0.6673964025651704, "lambda_domain": 0.6673964025651704, "layer_weights": [0.0929488092660904, 0.09158741682767868, 0.08931146562099457, 0.09644053131341934, 0.1084040179848671, 0.10017324239015579, 0.09403808414936066, 0.08813454955816269, 0.07760462909936905, 0.05994017422199249, 0.05358061194419861, 0.0478365533053875], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T10:34:19.495472Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=8, train_loss=1.4102, val_eer=0.0468"}
{"timestamp": "2026-02-09T10:34:19.529078Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 9: lambda_grl=0.719135, lambda_domain_loss=0.719135"}
{"timestamp": "2026-02-09T10:46:34.441761Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.6% (13072/25856 samples coded)"}
{"timestamp": "2026-02-09T10:58:10.817680Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.3% (25890/51456 samples coded)"}
{"timestamp": "2026-02-09T11:09:15.624150Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 50.2% (38696/77056 samples coded)"}
{"timestamp": "2026-02-09T11:21:08.228939Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.2% (51492/102656 samples coded)"}
{"timestamp": "2026-02-09T11:32:02.368877Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.1% (64238/128256 samples coded)"}
{"timestamp": "2026-02-09T11:43:43.546564Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.1% (77013/153856 samples coded)"}
{"timestamp": "2026-02-09T11:54:21.702363Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.0% (89701/179456 samples coded)"}
{"timestamp": "2026-02-09T11:55:15.142728Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 9 train: loss=1.5133, task_acc=1.0000"}
{"timestamp": "2026-02-09T11:58:47.842999Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 9 val: loss=0.7081, eer=0.0467, min_dcf=0.3962"}
{"timestamp": "2026-02-09T11:58:47.884788Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 9, "duration_sec": 5068.36, "train": {"loss": 1.5132645537679115, "task_loss": 0.0003108338191978373, "task_acc": 0.999950623244382, "codec_loss": 0.6917228245835626, "codec_q_loss": 1.4121297157547448, "codec_acc": 0.6897054950842697, "codec_q_acc": 0.1533203125, "aug_rate": 0.49990124648876405, "grad_norm_mean": 2.2877234620963605, "grad_norm_max": 7.39229800821485, "grad_clips": 712, "nan_grads": 0}, "is_best": false, "val": {"loss": 0.7081187188408985, "task_loss": 0.7081187188408985, "task_acc": 0.7946091387319478, "eer": 0.04666073882995269, "min_dcf": 0.3962080477959874}, "learning_rate": 4.724585183061158e-05, "lambda_grl": 0.7191348914970344, "lambda_domain_loss": 0.7191348914970344, "lambda_domain": 0.7191348914970344, "layer_weights": [0.08959557861089706, 0.08856458961963654, 0.0865420550107956, 0.09537556022405624, 0.11055302619934082, 0.10242139548063278, 0.09648245573043823, 0.09051630645990372, 0.07902220636606216, 0.059921566396951675, 0.05342848226428032, 0.04757673293352127], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T11:58:47.885038Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=9, train_loss=1.5133, val_eer=0.0467"}
{"timestamp": "2026-02-09T11:58:47.886205Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 10: lambda_grl=0.763978, lambda_domain_loss=0.763978"}
{"timestamp": "2026-02-09T12:10:31.008238Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 49.4% (12770/25856 samples coded)"}
{"timestamp": "2026-02-09T12:22:03.082087Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 49.7% (25565/51456 samples coded)"}
{"timestamp": "2026-02-09T12:33:20.415792Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 49.8% (38412/77056 samples coded)"}
{"timestamp": "2026-02-09T12:44:44.467964Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 49.8% (51115/102656 samples coded)"}
{"timestamp": "2026-02-09T12:56:01.310333Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 49.7% (63747/128256 samples coded)"}
{"timestamp": "2026-02-09T13:07:03.380314Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 49.7% (76528/153856 samples coded)"}
{"timestamp": "2026-02-09T13:18:39.693383Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 49.8% (89372/179456 samples coded)"}
{"timestamp": "2026-02-09T13:19:33.280911Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 10 train: loss=1.6012, task_acc=0.9999"}
{"timestamp": "2026-02-09T13:23:05.854955Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 10 val: loss=0.5896, eer=0.0471, min_dcf=0.3810"}
{"timestamp": "2026-02-09T13:23:05.869755Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 10, "duration_sec": 5057.98, "train": {"loss": 1.6012221507811815, "task_loss": 0.0003117774068616118, "task_acc": 0.9999286780196629, "codec_loss": 0.6858444624904836, "codec_q_loss": 1.4096476397152697, "codec_acc": 0.6912416608146067, "codec_q_acc": 0.15344101123595505, "aug_rate": 0.49812916959269665, "grad_norm_mean": 2.574857301896117, "grad_norm_max": 7.129864877506914, "grad_clips": 712, "nan_grads": 0}, "is_best": false, "val": {"loss": 0.5895689749674442, "task_loss": 0.5895689749674442, "task_acc": 0.8258558302955489, "eer": 0.04710764584924172, "min_dcf": 0.3810350468060085}, "per_codec": {"NONE": {"eer": 0.04710764584924172, "n_samples": 140950}}, "per_codec_q": {"NONE": {"eer": 0.04710764584924172, "n_samples": 140950}}, "learning_rate": 4.644692517146953e-05, "lambda_grl": 0.763978214396207, "lambda_domain_loss": 0.763978214396207, "lambda_domain": 0.763978214396207, "layer_weights": [0.08640365302562714, 0.08565717190504074, 0.08386150747537613, 0.09424952417612076, 0.11250899732112885, 0.10466033220291138, 0.0989433228969574, 0.09291894733905792, 0.08042214065790176, 0.05986892431974411, 0.053236134350299835, 0.04726935550570488], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T13:23:05.870017Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=10, train_loss=1.6012, val_eer=0.0471"}
{"timestamp": "2026-02-09T13:23:06.356516Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 11: lambda_grl=0.802494, lambda_domain_loss=0.802494"}
{"timestamp": "2026-02-09T13:35:32.856554Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 49.9% (12914/25856 samples coded)"}
{"timestamp": "2026-02-09T13:48:26.936305Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 49.8% (25645/51456 samples coded)"}
{"timestamp": "2026-02-09T14:00:14.893830Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 50.0% (38529/77056 samples coded)"}
{"timestamp": "2026-02-09T14:12:53.726496Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.1% (51408/102656 samples coded)"}
{"timestamp": "2026-02-09T14:24:22.360926Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.0% (64068/128256 samples coded)"}
{"timestamp": "2026-02-09T14:37:02.281150Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.0% (76868/153856 samples coded)"}
{"timestamp": "2026-02-09T14:48:34.040345Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.0% (89640/179456 samples coded)"}
{"timestamp": "2026-02-09T14:49:42.491111Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 11 train: loss=1.6815, task_acc=0.9999"}
{"timestamp": "2026-02-09T14:53:15.196792Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 11 val: loss=0.9404, eer=0.0487, min_dcf=0.4110"}
{"timestamp": "2026-02-09T14:53:15.225080Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 11, "duration_sec": 5408.87, "train": {"loss": 1.6814526445075366, "task_loss": 0.00029829383576848007, "task_acc": 0.9999396506320225, "codec_loss": 0.6833422459410817, "codec_q_loss": 1.4115696792187316, "codec_acc": 0.6922346822331461, "codec_q_acc": 0.15273876404494383, "aug_rate": 0.499561095505618, "grad_norm_mean": 2.8770068853669124, "grad_norm_max": 7.688921802248599, "grad_clips": 712, "nan_grads": 0}, "is_best": false, "val": {"loss": 0.9403763653578646, "task_loss": 0.9403763653578646, "task_acc": 0.7561454552271405, "eer": 0.048733383587701254, "min_dcf": 0.4110303161793552}, "learning_rate": 4.555519999002859e-05, "lambda_grl": 0.8024940315430233, "lambda_domain_loss": 0.8024940315430233, "lambda_domain": 0.8024940315430233, "layer_weights": [0.08335128426551819, 0.08286526054143906, 0.08124223351478577, 0.0929928869009018, 0.11447958648204803, 0.10687167197465897, 0.10144937038421631, 0.09529559314250946, 0.08171424269676208, 0.05974862352013588, 0.05300172045826912, 0.04698743298649788], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T14:53:15.225332Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=11, train_loss=1.6815, val_eer=0.0487"}
{"timestamp": "2026-02-09T14:53:15.226441Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 12: lambda_grl=0.835318, lambda_domain_loss=0.835318"}
{"timestamp": "2026-02-09T15:05:49.562803Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 49.9% (12890/25856 samples coded)"}
{"timestamp": "2026-02-09T15:18:13.330265Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 49.6% (25537/51456 samples coded)"}
{"timestamp": "2026-02-09T15:29:58.266411Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 49.9% (38420/77056 samples coded)"}
{"timestamp": "2026-02-09T15:41:54.505471Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.0% (51342/102656 samples coded)"}
{"timestamp": "2026-02-09T15:54:21.224473Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.1% (64253/128256 samples coded)"}
{"timestamp": "2026-02-09T16:06:07.777930Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.0% (76996/153856 samples coded)"}
{"timestamp": "2026-02-09T16:18:29.413173Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.0% (89791/179456 samples coded)"}
{"timestamp": "2026-02-09T16:19:24.101746Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 12 train: loss=1.7421, task_acc=0.9999"}
{"timestamp": "2026-02-09T16:22:56.761170Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 12 val: loss=0.7192, eer=0.0498, min_dcf=0.4100"}
{"timestamp": "2026-02-09T16:22:56.772899Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 12, "duration_sec": 5381.55, "train": {"loss": 1.7420953530608938, "task_loss": 0.00033037977401642073, "task_acc": 0.9999451369382022, "codec_loss": 0.6784656434581521, "codec_q_loss": 1.4066861060897955, "codec_acc": 0.6948022735252809, "codec_q_acc": 0.1530734287219101, "aug_rate": 0.5002029933286517, "grad_norm_mean": 3.097199316998993, "grad_norm_max": 11.305454295521445, "grad_clips": 712, "nan_grads": 0}, "is_best": false, "val": {"loss": 0.7192454538198219, "task_loss": 0.7192454538198219, "task_acc": 0.8062428161366665, "eer": 0.04975488534607619, "min_dcf": 0.40999500072749134}, "learning_rate": 4.457462678396122e-05, "lambda_grl": 0.8353180609420338, "lambda_domain_loss": 0.8353180609420338, "lambda_domain": 0.8353180609420338, "layer_weights": [0.08050841838121414, 0.08026563376188278, 0.07874846458435059, 0.09157173335552216, 0.11627400666475296, 0.10902685672044754, 0.10392477363348007, 0.0976669192314148, 0.0829428881406784, 0.05964098125696182, 0.05275913327932358, 0.04667021334171295], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T16:22:56.773160Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=12, train_loss=1.7421, val_eer=0.0498"}
{"timestamp": "2026-02-09T16:22:56.774292Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 13: lambda_grl=0.863106, lambda_domain_loss=0.863106"}
{"timestamp": "2026-02-09T16:35:17.634291Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.0% (12919/25856 samples coded)"}
{"timestamp": "2026-02-09T16:47:22.801175Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.0% (25731/51456 samples coded)"}
{"timestamp": "2026-02-09T16:59:36.740048Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 49.7% (38331/77056 samples coded)"}
{"timestamp": "2026-02-09T17:11:48.107870Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 49.9% (51241/102656 samples coded)"}
{"timestamp": "2026-02-09T17:24:10.809757Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 49.9% (64046/128256 samples coded)"}
{"timestamp": "2026-02-09T17:35:21.047810Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 49.9% (76824/153856 samples coded)"}
{"timestamp": "2026-02-09T17:47:22.296690Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.0% (89790/179456 samples coded)"}
{"timestamp": "2026-02-09T17:48:14.221981Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 13 train: loss=1.8043, task_acc=1.0000"}
{"timestamp": "2026-02-09T17:51:46.584461Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 13 val: loss=0.7434, eer=0.0454, min_dcf=0.3891"}
{"timestamp": "2026-02-09T17:51:46.605352Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 13, "duration_sec": 5329.83, "train": {"loss": 1.8043104148982616, "task_loss": 0.00017678405415666204, "task_acc": 0.9999561095505618, "codec_loss": 0.67942266258296, "codec_q_loss": 1.4108579363046068, "codec_acc": 0.6929753335674157, "codec_q_acc": 0.15257966116573032, "aug_rate": 0.5001371576544944, "grad_norm_mean": 3.430442143863166, "grad_norm_max": 10.955236370891736, "grad_clips": 712, "nan_grads": 0}, "is_best": false, "val": {"loss": 0.743362751121746, "task_loss": 0.743362751121746, "task_acc": 0.8078754537767594, "eer": 0.04538386163198402, "min_dcf": 0.3890680470076117}, "learning_rate": 4.3509549663144325e-05, "lambda_grl": 0.8631059277201735, "lambda_domain_loss": 0.8631059277201735, "lambda_domain": 0.8631059277201735, "layer_weights": [0.07782264798879623, 0.0778232216835022, 0.07641135901212692, 0.09022440761327744, 0.11801579594612122, 0.11113506555557251, 0.10625237226486206, 0.09997681528329849, 0.08404302597045898, 0.05946886166930199, 0.05248922482132912, 0.04633714631199837], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T17:51:46.605761Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=13, train_loss=1.8043, val_eer=0.0454"}
{"timestamp": "2026-02-09T17:51:46.606876Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 14: lambda_grl=0.886498, lambda_domain_loss=0.886498"}
{"timestamp": "2026-02-09T18:04:41.479115Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.6% (13083/25856 samples coded)"}
{"timestamp": "2026-02-09T18:16:42.465855Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.2% (25812/51456 samples coded)"}
{"timestamp": "2026-02-09T18:28:36.939759Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 50.2% (38672/77056 samples coded)"}
{"timestamp": "2026-02-09T18:40:54.359357Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.1% (51383/102656 samples coded)"}
{"timestamp": "2026-02-09T18:53:09.464107Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.1% (64246/128256 samples coded)"}
{"timestamp": "2026-02-09T19:04:27.311239Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.1% (77045/153856 samples coded)"}
{"timestamp": "2026-02-09T19:16:22.018309Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.0% (89685/179456 samples coded)"}
{"timestamp": "2026-02-09T19:17:17.018467Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 14 train: loss=1.8477, task_acc=0.9999"}
{"timestamp": "2026-02-09T19:20:49.501959Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 14 val: loss=0.9243, eer=0.0445, min_dcf=0.3743"}
{"timestamp": "2026-02-09T19:20:50.008719Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "New best eer: 0.0445"}
{"timestamp": "2026-02-09T19:20:50.009500Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 14, "duration_sec": 5343.4, "train": {"loss": 1.8477245545789096, "task_loss": 0.00020627394891775612, "task_acc": 0.9999341643258427, "codec_loss": 0.6790993570276861, "codec_q_loss": 1.4049639616454586, "codec_acc": 0.6924486481741573, "codec_q_acc": 0.15480161516853932, "aug_rate": 0.49978603405898875, "grad_norm_mean": 3.640607946302549, "grad_norm_max": 12.439928022091971, "grad_clips": 712, "nan_grads": 0}, "is_best": true, "val": {"loss": 0.9242740289701957, "task_loss": 0.9242740289701957, "task_acc": 0.777137118112803, "eer": 0.04451968883440466, "min_dcf": 0.37429147858234774}, "learning_rate": 4.236468710449697e-05, "lambda_grl": 0.88649813172024, "lambda_domain_loss": 0.88649813172024, "lambda_domain": 0.88649813172024, "layer_weights": [0.07529604434967041, 0.07549629360437393, 0.07418308407068253, 0.0888260081410408, 0.11965516209602356, 0.11314652115106583, 0.10856550931930542, 0.10220260918140411, 0.08512227237224579, 0.05931014195084572, 0.05220764875411987, 0.04598864167928696], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T19:20:50.009961Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=14, train_loss=1.8477, val_eer=0.0445"}
{"timestamp": "2026-02-09T19:20:50.011485Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 15: lambda_grl=0.906097, lambda_domain_loss=0.906097"}
{"timestamp": "2026-02-09T19:33:22.759204Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.2% (12969/25856 samples coded)"}
