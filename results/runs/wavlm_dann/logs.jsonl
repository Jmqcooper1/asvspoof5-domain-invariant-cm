{"timestamp": "2026-02-08T11:29:57.122671Z", "level": "INFO", "logger": "__main__", "message": "Run directory: /projects/prjs1904/runs/wavlm_dann"}
{"timestamp": "2026-02-08T11:29:59.250071Z", "level": "INFO", "logger": "__main__", "message": "Git commit: 5e88564a"}
{"timestamp": "2026-02-08T11:29:59.250228Z", "level": "INFO", "logger": "__main__", "message": "Hardware: NVIDIA A100-SXM4-40GB"}
{"timestamp": "2026-02-08T11:29:59.250759Z", "level": "INFO", "logger": "__main__", "message": "CODEC classes (manifest): 12"}
{"timestamp": "2026-02-08T11:29:59.250858Z", "level": "INFO", "logger": "__main__", "message": "CODEC_Q classes (manifest): 9"}
{"timestamp": "2026-02-08T11:29:59.262808Z", "level": "INFO", "logger": "__main__", "message": "Using AUGMENTATION_CACHE_DIR from environment: /scratch-shared/jcooper/asvspoof5_augmented_cache"}
{"timestamp": "2026-02-08T11:29:59.439278Z", "level": "WARNING", "logger": "asvspoof5_domain_invariant_cm.data.codec_augment", "message": "Some requested codecs not supported by ffmpeg: {'OPUS'}. Using: ['MP3', 'AAC']"}
{"timestamp": "2026-02-08T11:29:59.439398Z", "level": "INFO", "logger": "__main__", "message": "Codec augmentor initialized: supported_codecs=['MP3', 'AAC'], codec_prob=0.5"}
{"timestamp": "2026-02-08T11:29:59.624674Z", "level": "INFO", "logger": "__main__", "message": "Train samples: 182357"}
{"timestamp": "2026-02-08T11:29:59.624828Z", "level": "INFO", "logger": "__main__", "message": "Val samples: 140950"}
{"timestamp": "2026-02-08T11:29:59.625193Z", "level": "INFO", "logger": "__main__", "message": "DANN with augmentation: domain discriminator sizes num_codecs=3, num_codec_qs=6"}
{"timestamp": "2026-02-08T11:29:59.628042Z", "level": "INFO", "logger": "__main__", "message": "Saved synthetic vocabs to run dir (DANN with augmentation)"}
{"timestamp": "2026-02-08T11:30:02.657309Z", "level": "INFO", "logger": "__main__", "message": "Total parameters: 96,354,951"}
{"timestamp": "2026-02-08T11:30:02.657474Z", "level": "INFO", "logger": "__main__", "message": "Trainable parameters: 1,973,015"}
{"timestamp": "2026-02-08T11:30:06.407493Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "Wandb initialized: https://wandb.ai/mike-cooper-uva/asvspoof5-dann/runs/omz5omuu"}
{"timestamp": "2026-02-08T11:30:06.410170Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "Model: 96,354,951 params (1,973,015 trainable)"}
{"timestamp": "2026-02-08T11:30:06.410676Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "Dataset: train=182357, val=140950"}
{"timestamp": "2026-02-08T11:30:06.411612Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[experiment_start]", "event_type": "experiment_start", "data": {"method": "dann", "backbone": "wavlm_base_plus", "max_epochs": 50, "batch_size": 256, "learning_rate": 0.0001, "model": {"total_params": 96354951, "trainable_params": 1973015}, "dataset": {"train_size": 182357, "val_size": 140950}, "dann": {"lambda_init": 0.01, "lambda_schedule": {"enabled": true, "type": "exponential", "start": 0.01, "end": 1.0, "warmup_epochs": 0}}}}
{"timestamp": "2026-02-08T11:30:06.411803Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[experiment_start] method=dann, backbone=wavlm_base_plus"}
{"timestamp": "2026-02-08T11:30:06.411990Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Starting training for 50 epochs"}
{"timestamp": "2026-02-08T11:30:06.412210Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Run directory: /projects/prjs1904/runs/wavlm_dann"}
{"timestamp": "2026-02-08T11:30:06.412371Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Model: 96,354,951 params (1,973,015 trainable)"}
{"timestamp": "2026-02-08T11:30:06.414149Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Dataset: train=182357, val=140950"}
{"timestamp": "2026-02-08T11:30:06.419151Z", "level": "INFO", "logger": "__main__", "message": "============================================================"}
{"timestamp": "2026-02-08T11:30:06.419365Z", "level": "INFO", "logger": "__main__", "message": "Training DANN model"}
{"timestamp": "2026-02-08T11:30:06.419566Z", "level": "INFO", "logger": "__main__", "message": "Backbone: wavlm_base_plus"}
{"timestamp": "2026-02-08T11:30:06.419789Z", "level": "INFO", "logger": "__main__", "message": "Seed: 42"}
{"timestamp": "2026-02-08T11:30:06.419988Z", "level": "INFO", "logger": "__main__", "message": "============================================================"}
{"timestamp": "2026-02-08T11:30:06.420205Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 0: lambda_grl=0.010000, lambda_domain_loss=0.010000"}
{"timestamp": "2026-02-08T11:41:29.639506Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.2% (12988/25856 samples coded)"}
{"timestamp": "2026-02-08T11:52:22.198528Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.0% (25745/51456 samples coded)"}
{"timestamp": "2026-02-08T12:02:49.306218Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 49.9% (38432/77056 samples coded)"}
{"timestamp": "2026-02-08T12:14:08.686275Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.0% (51356/102656 samples coded)"}
{"timestamp": "2026-02-08T12:24:56.525474Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.0% (64126/128256 samples coded)"}
{"timestamp": "2026-02-08T12:36:12.215132Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.1% (77078/153856 samples coded)"}
{"timestamp": "2026-02-08T12:46:43.083719Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.0% (89801/179456 samples coded)"}
{"timestamp": "2026-02-08T12:47:43.656394Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 0 train: loss=0.2323, task_acc=0.9202"}
{"timestamp": "2026-02-08T12:52:39.353161Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 0 val: loss=0.2986, eer=0.0519, min_dcf=0.4892"}
{"timestamp": "2026-02-08T12:52:39.791959Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "New best eer: 0.0519"}
{"timestamp": "2026-02-08T12:52:39.792879Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 0, "duration_sec": 4953.37, "train": {"loss": 0.2322726505625407, "task_loss": 0.2053786715802611, "task_acc": 0.920240080758427, "codec_loss": 1.0436281099748075, "codec_q_loss": 1.6457698758733406, "codec_acc": 0.4854887201544944, "codec_q_acc": 0.11237600948033707, "aug_rate": 0.5003566099016854, "grad_norm_mean": 0.31520390877838317, "grad_norm_max": 1.224317988967967, "grad_clips": 65, "nan_grads": 0}, "is_best": true, "val": {"loss": 0.2986341169925437, "task_loss": 0.2986341169925437, "task_acc": 0.8802652375235099, "eer": 0.05192557658262292, "min_dcf": 0.48922689126472585}, "per_codec": {"NONE": {"eer": 0.05192557658262292, "n_samples": 140950}}, "per_codec_q": {"NONE": {"eer": 0.05192557658262292, "n_samples": 140950}}, "learning_rate": 9.999108914437816e-05, "lambda_grl": 0.01, "lambda_domain_loss": 0.01, "lambda_domain": 0.01, "layer_weights": [0.12493493407964706, 0.11368090659379959, 0.10838069766759872, 0.1008586585521698, 0.09195458143949509, 0.08495810627937317, 0.07705159485340118, 0.07031817734241486, 0.06532572209835052, 0.05968865379691124, 0.05420438572764397, 0.04864361509680748], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-08T12:52:39.793374Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=0, train_loss=0.2323, val_eer=0.0519"}
{"timestamp": "2026-02-08T12:52:40.167243Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 1: lambda_grl=0.108671, lambda_domain_loss=0.108671"}
{"timestamp": "2026-02-08T13:03:46.922190Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 49.7% (12860/25856 samples coded)"}
{"timestamp": "2026-02-08T13:14:22.775570Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 49.8% (25604/51456 samples coded)"}
{"timestamp": "2026-02-08T13:24:57.266074Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 49.8% (38350/77056 samples coded)"}
{"timestamp": "2026-02-08T13:36:02.373628Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 49.8% (51104/102656 samples coded)"}
{"timestamp": "2026-02-08T13:46:50.476056Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 49.8% (63867/128256 samples coded)"}
{"timestamp": "2026-02-08T13:58:13.337107Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 49.9% (76749/153856 samples coded)"}
{"timestamp": "2026-02-08T14:09:25.362200Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 49.9% (89573/179456 samples coded)"}
{"timestamp": "2026-02-08T14:10:41.248389Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 1 train: loss=0.2569, task_acc=0.9997"}
{"timestamp": "2026-02-08T14:15:29.268189Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 1 val: loss=0.4695, eer=0.0346, min_dcf=0.3078"}
{"timestamp": "2026-02-08T14:15:29.671417Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "New best eer: 0.0346"}
{"timestamp": "2026-02-08T14:15:29.672142Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 1, "duration_sec": 4969.5, "train": {"loss": 0.25685685745367176, "task_loss": 0.002773404894448984, "task_acc": 0.9996872805477528, "codec_loss": 0.8265666826052612, "codec_q_loss": 1.511524574475342, "codec_acc": 0.6326698560393258, "codec_q_acc": 0.13911077949438203, "aug_rate": 0.4993745610955056, "grad_norm_mean": 0.16932263258681854, "grad_norm_max": 0.5073716868060564, "grad_clips": 0, "nan_grads": 0}, "is_best": true, "val": {"loss": 0.46950042253180985, "task_loss": 0.46950042253180985, "task_acc": 0.8223232381356823, "eer": 0.034628451928048525, "min_dcf": 0.3077845641588305}, "learning_rate": 9.983081684820173e-05, "lambda_grl": 0.10867131467870633, "lambda_domain_loss": 0.10867131467870633, "lambda_domain": 0.10867131467870633, "layer_weights": [0.12215963006019592, 0.1136300340294838, 0.10890893638134003, 0.10266047716140747, 0.09349171817302704, 0.08591610938310623, 0.0769188329577446, 0.06993842124938965, 0.06508752703666687, 0.05940072610974312, 0.053897611796855927, 0.047990042716264725], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-08T14:15:29.672454Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=1, train_loss=0.2569, val_eer=0.0346"}
{"timestamp": "2026-02-08T14:15:29.673659Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 2: lambda_grl=0.205402, lambda_domain_loss=0.205402"}
{"timestamp": "2026-02-08T14:26:40.919130Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 49.5% (12787/25856 samples coded)"}
{"timestamp": "2026-02-08T14:37:52.827002Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.1% (25792/51456 samples coded)"}
{"timestamp": "2026-02-08T14:48:32.105546Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 50.1% (38582/77056 samples coded)"}
{"timestamp": "2026-02-08T14:59:50.153021Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.0% (51371/102656 samples coded)"}
{"timestamp": "2026-02-08T15:10:25.896079Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.0% (64156/128256 samples coded)"}
{"timestamp": "2026-02-08T15:20:55.251691Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.0% (76925/153856 samples coded)"}
{"timestamp": "2026-02-08T15:32:06.995473Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.1% (89877/179456 samples coded)"}
{"timestamp": "2026-02-08T15:32:47.539331Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 2 train: loss=0.4290, task_acc=0.9999"}
{"timestamp": "2026-02-08T15:37:31.345986Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 2 val: loss=0.5714, eer=0.0338, min_dcf=0.3029"}
{"timestamp": "2026-02-08T15:37:31.365792Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 2, "duration_sec": 4921.69, "train": {"loss": 0.42902377632896554, "task_loss": 0.0007620260604720018, "task_acc": 0.9999396506320225, "codec_loss": 0.6501647525289086, "codec_q_loss": 1.434832704368602, "codec_acc": 0.7152277914325843, "codec_q_acc": 0.15020409058988765, "aug_rate": 0.5008723226825843, "grad_norm_mean": 0.5145571056725387, "grad_norm_max": 1.4975693554191691, "grad_clips": 38, "nan_grads": 0}, "is_best": false, "val": {"loss": 0.5714258129172662, "task_loss": 0.5714258129172662, "task_acc": 0.8062052896580981, "eer": 0.03380304312726993, "min_dcf": 0.30287329331505414}, "learning_rate": 9.947027412453421e-05, "lambda_grl": 0.20540156702265497, "lambda_domain_loss": 0.20540156702265497, "lambda_domain": 0.20540156702265497, "layer_weights": [0.11057164520025253, 0.11105787009000778, 0.1065446138381958, 0.10416622459888458, 0.09851337224245071, 0.08945624530315399, 0.07904911041259766, 0.07149207592010498, 0.06651802361011505, 0.06060546636581421, 0.05408291891217232, 0.04794246703386307], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-08T15:37:31.366066Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=2, train_loss=0.4290, val_eer=0.0338"}
{"timestamp": "2026-02-08T15:37:31.367252Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 3: lambda_grl=0.298399, lambda_domain_loss=0.298399"}
{"timestamp": "2026-02-08T15:48:39.953662Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.0% (12930/25856 samples coded)"}
{"timestamp": "2026-02-08T15:59:15.977822Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.0% (25731/51456 samples coded)"}
{"timestamp": "2026-02-08T16:09:52.878065Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 50.0% (38520/77056 samples coded)"}
{"timestamp": "2026-02-08T16:20:05.730272Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 49.8% (51174/102656 samples coded)"}
{"timestamp": "2026-02-08T16:31:10.393369Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 49.9% (63975/128256 samples coded)"}
{"timestamp": "2026-02-08T16:42:15.517590Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 49.9% (76845/153856 samples coded)"}
{"timestamp": "2026-02-08T16:52:52.018820Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.0% (89683/179456 samples coded)"}
{"timestamp": "2026-02-08T16:53:40.116121Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 3 train: loss=0.6046, task_acc=1.0000"}
{"timestamp": "2026-02-08T16:58:23.835338Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 3 val: loss=0.6910, eer=0.0330, min_dcf=0.3038"}
{"timestamp": "2026-02-08T16:58:24.295262Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "New best eer: 0.0330"}
{"timestamp": "2026-02-08T16:58:24.296071Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 3, "duration_sec": 4852.93, "train": {"loss": 0.6045712323838406, "task_loss": 0.00038332141035895667, "task_acc": 0.9999835410814607, "codec_loss": 0.6139590763225314, "codec_q_loss": 1.410802878355712, "codec_acc": 0.7266393082865169, "codec_q_acc": 0.1520968662219101, "aug_rate": 0.4994019926264045, "grad_norm_mean": 0.9513450059992443, "grad_norm_max": 3.048507019825889, "grad_clips": 274, "nan_grads": 0}, "is_best": true, "val": {"loss": 0.6909743085530622, "task_loss": 0.6909743085530622, "task_acc": 0.7874955573878141, "eer": 0.03303235543058769, "min_dcf": 0.3038222479985185}, "learning_rate": 9.891092468409455e-05, "lambda_grl": 0.2983994863270749, "lambda_domain_loss": 0.2983994863270749, "lambda_domain": 0.2983994863270749, "layer_weights": [0.09952402859926224, 0.1076495349407196, 0.101507268846035, 0.10630115121603012, 0.10243210196495056, 0.09237536042928696, 0.08109362423419952, 0.07368821650743484, 0.06936231255531311, 0.0629514828324318, 0.054606810212135315, 0.04850815609097481], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-08T16:58:24.296375Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=3, train_loss=0.6046, val_eer=0.0330"}
{"timestamp": "2026-02-08T16:58:24.297639Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 4: lambda_grl=0.386149, lambda_domain_loss=0.386149"}
{"timestamp": "2026-02-08T17:09:44.371726Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.4% (13027/25856 samples coded)"}
{"timestamp": "2026-02-08T17:20:43.563298Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.3% (25902/51456 samples coded)"}
{"timestamp": "2026-02-08T21:50:10.625766Z", "level": "INFO", "logger": "__main__", "message": "Run directory: /projects/prjs1904/runs/wavlm_dann"}
{"timestamp": "2026-02-08T21:50:12.243166Z", "level": "INFO", "logger": "__main__", "message": "Git commit: 524ce14a"}
{"timestamp": "2026-02-08T21:50:12.243313Z", "level": "INFO", "logger": "__main__", "message": "Hardware: NVIDIA A100-SXM4-40GB"}
{"timestamp": "2026-02-08T21:50:12.260375Z", "level": "INFO", "logger": "__main__", "message": "CODEC classes (manifest): 12"}
{"timestamp": "2026-02-08T21:50:12.260486Z", "level": "INFO", "logger": "__main__", "message": "CODEC_Q classes (manifest): 9"}
{"timestamp": "2026-02-08T21:50:12.287156Z", "level": "INFO", "logger": "__main__", "message": "Using AUGMENTATION_CACHE_DIR from environment: /scratch-shared/jcooper/asvspoof5_augmented_cache"}
{"timestamp": "2026-02-08T21:50:12.470580Z", "level": "WARNING", "logger": "asvspoof5_domain_invariant_cm.data.codec_augment", "message": "Some requested codecs not supported by ffmpeg: {'OPUS'}. Using: ['MP3', 'AAC']"}
{"timestamp": "2026-02-08T21:50:12.470697Z", "level": "INFO", "logger": "__main__", "message": "Codec augmentor initialized: supported_codecs=['MP3', 'AAC'], codec_prob=0.5"}
{"timestamp": "2026-02-08T21:50:13.048615Z", "level": "INFO", "logger": "__main__", "message": "Train samples: 182357"}
{"timestamp": "2026-02-08T21:50:13.048757Z", "level": "INFO", "logger": "__main__", "message": "Val samples: 140950"}
{"timestamp": "2026-02-08T21:50:13.049107Z", "level": "INFO", "logger": "__main__", "message": "DANN with augmentation: domain discriminator sizes num_codecs=3, num_codec_qs=6"}
{"timestamp": "2026-02-08T21:50:13.062513Z", "level": "INFO", "logger": "__main__", "message": "Saved synthetic vocabs to run dir (DANN with augmentation)"}
{"timestamp": "2026-02-08T21:50:16.001378Z", "level": "INFO", "logger": "__main__", "message": "Total parameters: 96,354,951"}
{"timestamp": "2026-02-08T21:50:16.001539Z", "level": "INFO", "logger": "__main__", "message": "Trainable parameters: 1,973,015"}
{"timestamp": "2026-02-08T21:50:19.799524Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "Wandb initialized: https://wandb.ai/mike-cooper-uva/asvspoof5-dann/runs/vv8r6e3i"}
{"timestamp": "2026-02-08T21:50:19.802118Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "Model: 96,354,951 params (1,973,015 trainable)"}
{"timestamp": "2026-02-08T21:50:19.802612Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "Dataset: train=182357, val=140950"}
{"timestamp": "2026-02-08T21:50:19.815838Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[experiment_start]", "event_type": "experiment_start", "data": {"method": "dann", "backbone": "wavlm_base_plus", "max_epochs": 50, "batch_size": 512, "learning_rate": 0.0001, "model": {"total_params": 96354951, "trainable_params": 1973015}, "dataset": {"train_size": 182357, "val_size": 140950}, "dann": {"lambda_init": 0.01, "lambda_schedule": {"enabled": true, "type": "exponential", "start": 0.01, "end": 1.0, "warmup_epochs": 0}}}}
{"timestamp": "2026-02-08T21:50:19.816037Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[experiment_start] method=dann, backbone=wavlm_base_plus"}
{"timestamp": "2026-02-08T21:50:19.816228Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Starting training for 50 epochs"}
{"timestamp": "2026-02-08T21:50:19.816415Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Run directory: /projects/prjs1904/runs/wavlm_dann"}
{"timestamp": "2026-02-08T21:50:19.816601Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Model: 96,354,951 params (1,973,015 trainable)"}
{"timestamp": "2026-02-08T21:50:19.816788Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Dataset: train=182357, val=140950"}
{"timestamp": "2026-02-08T21:50:19.822269Z", "level": "INFO", "logger": "__main__", "message": "============================================================"}
{"timestamp": "2026-02-08T21:50:19.822486Z", "level": "INFO", "logger": "__main__", "message": "Training DANN model"}
{"timestamp": "2026-02-08T21:50:19.822693Z", "level": "INFO", "logger": "__main__", "message": "Backbone: wavlm_base_plus"}
{"timestamp": "2026-02-08T21:50:19.822887Z", "level": "INFO", "logger": "__main__", "message": "Seed: 42"}
{"timestamp": "2026-02-08T21:50:19.823078Z", "level": "INFO", "logger": "__main__", "message": "============================================================"}
{"timestamp": "2026-02-08T21:50:19.823314Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 0: lambda_grl=0.010000, lambda_domain_loss=0.010000"}
{"timestamp": "2026-02-08T22:05:53.700560Z", "level": "INFO", "logger": "__main__", "message": "Run directory: /projects/prjs1904/runs/wavlm_dann"}
{"timestamp": "2026-02-08T22:05:54.832364Z", "level": "INFO", "logger": "__main__", "message": "Git commit: 65bf061a"}
{"timestamp": "2026-02-08T22:05:54.832511Z", "level": "INFO", "logger": "__main__", "message": "Hardware: NVIDIA A100-SXM4-40GB"}
{"timestamp": "2026-02-08T22:05:54.833182Z", "level": "INFO", "logger": "__main__", "message": "CODEC classes (manifest): 12"}
{"timestamp": "2026-02-08T22:05:54.833282Z", "level": "INFO", "logger": "__main__", "message": "CODEC_Q classes (manifest): 9"}
{"timestamp": "2026-02-08T22:05:54.833505Z", "level": "INFO", "logger": "__main__", "message": "Using AUGMENTATION_CACHE_DIR from environment: /scratch-shared/jcooper/asvspoof5_augmented_cache"}
{"timestamp": "2026-02-08T22:05:55.008135Z", "level": "WARNING", "logger": "asvspoof5_domain_invariant_cm.data.codec_augment", "message": "Some requested codecs not supported by ffmpeg: {'OPUS'}. Using: ['MP3', 'AAC']"}
{"timestamp": "2026-02-08T22:05:55.008248Z", "level": "INFO", "logger": "__main__", "message": "Codec augmentor initialized: supported_codecs=['MP3', 'AAC'], codec_prob=0.5"}
{"timestamp": "2026-02-08T22:05:55.267526Z", "level": "INFO", "logger": "__main__", "message": "Train samples: 182357"}
{"timestamp": "2026-02-08T22:05:55.267671Z", "level": "INFO", "logger": "__main__", "message": "Val samples: 140950"}
{"timestamp": "2026-02-08T22:05:55.268030Z", "level": "INFO", "logger": "__main__", "message": "DANN with augmentation: domain discriminator sizes num_codecs=3, num_codec_qs=6"}
{"timestamp": "2026-02-08T22:05:55.269390Z", "level": "INFO", "logger": "__main__", "message": "Saved synthetic vocabs to run dir (DANN with augmentation)"}
{"timestamp": "2026-02-08T22:05:57.734060Z", "level": "INFO", "logger": "__main__", "message": "Total parameters: 96,354,951"}
{"timestamp": "2026-02-08T22:05:57.734216Z", "level": "INFO", "logger": "__main__", "message": "Trainable parameters: 1,973,015"}
{"timestamp": "2026-02-08T22:05:59.295512Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "Wandb initialized: https://wandb.ai/mike-cooper-uva/asvspoof5-dann/runs/o27myx42"}
{"timestamp": "2026-02-08T22:05:59.298153Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "Model: 96,354,951 params (1,973,015 trainable)"}
{"timestamp": "2026-02-08T22:05:59.298790Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "Dataset: train=182357, val=140950"}
{"timestamp": "2026-02-08T22:05:59.299688Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[experiment_start]", "event_type": "experiment_start", "data": {"method": "dann", "backbone": "wavlm_base_plus", "max_epochs": 50, "batch_size": 256, "learning_rate": 0.0001, "model": {"total_params": 96354951, "trainable_params": 1973015}, "dataset": {"train_size": 182357, "val_size": 140950}, "dann": {"lambda_init": 0.01, "lambda_schedule": {"enabled": true, "type": "exponential", "start": 0.01, "end": 1.0, "warmup_epochs": 0}}}}
{"timestamp": "2026-02-08T22:05:59.299896Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[experiment_start] method=dann, backbone=wavlm_base_plus"}
{"timestamp": "2026-02-08T22:05:59.300127Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Starting training for 50 epochs"}
{"timestamp": "2026-02-08T22:05:59.300623Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Run directory: /projects/prjs1904/runs/wavlm_dann"}
{"timestamp": "2026-02-08T22:05:59.300787Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Model: 96,354,951 params (1,973,015 trainable)"}
{"timestamp": "2026-02-08T22:05:59.300975Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Dataset: train=182357, val=140950"}
{"timestamp": "2026-02-08T22:05:59.305893Z", "level": "INFO", "logger": "__main__", "message": "============================================================"}
{"timestamp": "2026-02-08T22:05:59.306090Z", "level": "INFO", "logger": "__main__", "message": "Training DANN model"}
{"timestamp": "2026-02-08T22:05:59.306291Z", "level": "INFO", "logger": "__main__", "message": "Backbone: wavlm_base_plus"}
{"timestamp": "2026-02-08T22:05:59.306493Z", "level": "INFO", "logger": "__main__", "message": "Seed: 42"}
{"timestamp": "2026-02-08T22:05:59.306682Z", "level": "INFO", "logger": "__main__", "message": "============================================================"}
{"timestamp": "2026-02-08T22:05:59.306911Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 0: lambda_grl=0.010000, lambda_domain_loss=0.010000"}
{"timestamp": "2026-02-08T22:17:13.334749Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.2% (12988/25856 samples coded)"}
{"timestamp": "2026-02-08T22:28:10.806632Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.0% (25745/51456 samples coded)"}
{"timestamp": "2026-02-08T22:38:25.414959Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 49.9% (38432/77056 samples coded)"}
{"timestamp": "2026-02-08T22:49:56.794945Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.0% (51356/102656 samples coded)"}
{"timestamp": "2026-02-08T23:00:30.357974Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.0% (64126/128256 samples coded)"}
{"timestamp": "2026-02-08T23:11:38.278236Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.1% (77078/153856 samples coded)"}
{"timestamp": "2026-02-08T23:21:44.103561Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.0% (89801/179456 samples coded)"}
{"timestamp": "2026-02-08T23:22:45.715360Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 0 train: loss=0.2323, task_acc=0.9202"}
{"timestamp": "2026-02-08T23:27:43.291556Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 0 val: loss=0.2986, eer=0.0519, min_dcf=0.4892"}
{"timestamp": "2026-02-08T23:27:43.990566Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "New best eer: 0.0519"}
{"timestamp": "2026-02-08T23:27:43.991459Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 0, "duration_sec": 4904.68, "train": {"loss": 0.2322726505625407, "task_loss": 0.2053786715802611, "task_acc": 0.920240080758427, "codec_loss": 1.0436281099748075, "codec_q_loss": 1.6457698758733406, "codec_acc": 0.4854887201544944, "codec_q_acc": 0.11237600948033707, "aug_rate": 0.5003566099016854, "grad_norm_mean": 0.31520390877838317, "grad_norm_max": 1.224317988967967, "grad_clips": 65, "nan_grads": 0}, "is_best": true, "val": {"loss": 0.2986341169925437, "task_loss": 0.2986341169925437, "task_acc": 0.8802652375235099, "eer": 0.05192557658262292, "min_dcf": 0.48922689126472585}, "per_codec": {"NONE": {"eer": 0.05192557658262292, "n_samples": 140950}}, "per_codec_q": {"NONE": {"eer": 0.05192557658262292, "n_samples": 140950}}, "learning_rate": 9.999108914437816e-05, "lambda_grl": 0.01, "lambda_domain_loss": 0.01, "lambda_domain": 0.01, "layer_weights": [0.12493493407964706, 0.11368090659379959, 0.10838069766759872, 0.1008586585521698, 0.09195458143949509, 0.08495810627937317, 0.07705159485340118, 0.07031817734241486, 0.06532572209835052, 0.05968865379691124, 0.05420438572764397, 0.04864361509680748], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-08T23:27:44.018336Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=0, train_loss=0.2323, val_eer=0.0519"}
{"timestamp": "2026-02-08T23:27:44.353407Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 1: lambda_grl=0.108671, lambda_domain_loss=0.108671"}
{"timestamp": "2026-02-08T23:38:48.136440Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 49.7% (12860/25856 samples coded)"}
{"timestamp": "2026-02-08T23:49:26.954527Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 49.8% (25604/51456 samples coded)"}
{"timestamp": "2026-02-08T23:59:45.481415Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 49.8% (38350/77056 samples coded)"}
{"timestamp": "2026-02-09T00:10:24.784528Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 49.8% (51104/102656 samples coded)"}
{"timestamp": "2026-02-09T00:20:56.703126Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 49.8% (63867/128256 samples coded)"}
{"timestamp": "2026-02-09T00:31:39.409496Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 49.9% (76749/153856 samples coded)"}
{"timestamp": "2026-02-09T00:42:42.971101Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 49.9% (89573/179456 samples coded)"}
{"timestamp": "2026-02-09T00:43:40.389065Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 1 train: loss=0.2569, task_acc=0.9997"}
{"timestamp": "2026-02-09T00:48:25.334899Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 1 val: loss=0.4695, eer=0.0346, min_dcf=0.3078"}
{"timestamp": "2026-02-09T00:48:25.717385Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "New best eer: 0.0346"}
{"timestamp": "2026-02-09T00:48:25.718179Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 1, "duration_sec": 4841.36, "train": {"loss": 0.25685685745367176, "task_loss": 0.002773404894448984, "task_acc": 0.9996872805477528, "codec_loss": 0.8265666826052612, "codec_q_loss": 1.511524574475342, "codec_acc": 0.6326698560393258, "codec_q_acc": 0.13911077949438203, "aug_rate": 0.4993745610955056, "grad_norm_mean": 0.16932263258681854, "grad_norm_max": 0.5073716868060564, "grad_clips": 0, "nan_grads": 0}, "is_best": true, "val": {"loss": 0.46950042253180985, "task_loss": 0.46950042253180985, "task_acc": 0.8223232381356823, "eer": 0.034628451928048525, "min_dcf": 0.3077845641588305}, "learning_rate": 9.983081684820173e-05, "lambda_grl": 0.10867131467870633, "lambda_domain_loss": 0.10867131467870633, "lambda_domain": 0.10867131467870633, "layer_weights": [0.12215963006019592, 0.1136300340294838, 0.10890893638134003, 0.10266047716140747, 0.09349171817302704, 0.08591610938310623, 0.0769188329577446, 0.06993842124938965, 0.06508752703666687, 0.05940072610974312, 0.053897611796855927, 0.047990042716264725], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T00:48:25.718491Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=1, train_loss=0.2569, val_eer=0.0346"}
{"timestamp": "2026-02-09T00:48:25.719663Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 2: lambda_grl=0.205402, lambda_domain_loss=0.205402"}
{"timestamp": "2026-02-09T00:59:49.708195Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 49.5% (12787/25856 samples coded)"}
{"timestamp": "2026-02-09T01:11:01.417189Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.1% (25792/51456 samples coded)"}
{"timestamp": "2026-02-09T01:21:40.221974Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 50.1% (38582/77056 samples coded)"}
{"timestamp": "2026-02-09T01:32:58.712832Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.0% (51371/102656 samples coded)"}
{"timestamp": "2026-02-09T01:43:21.729604Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.0% (64156/128256 samples coded)"}
{"timestamp": "2026-02-09T01:53:54.919647Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.0% (76925/153856 samples coded)"}
{"timestamp": "2026-02-09T02:04:55.435488Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.1% (89877/179456 samples coded)"}
{"timestamp": "2026-02-09T02:05:38.507635Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 2 train: loss=0.4290, task_acc=0.9999"}
{"timestamp": "2026-02-09T02:10:29.323832Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 2 val: loss=0.5714, eer=0.0338, min_dcf=0.3029"}
{"timestamp": "2026-02-09T02:10:29.350091Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 2, "duration_sec": 4923.63, "train": {"loss": 0.42902377632896554, "task_loss": 0.0007620260604720018, "task_acc": 0.9999396506320225, "codec_loss": 0.6501647525289086, "codec_q_loss": 1.434832704368602, "codec_acc": 0.7152277914325843, "codec_q_acc": 0.15020409058988765, "aug_rate": 0.5008723226825843, "grad_norm_mean": 0.5145571056725387, "grad_norm_max": 1.4975693554191691, "grad_clips": 38, "nan_grads": 0}, "is_best": false, "val": {"loss": 0.5714258129172662, "task_loss": 0.5714258129172662, "task_acc": 0.8062052896580981, "eer": 0.03380304312726993, "min_dcf": 0.30287329331505414}, "learning_rate": 9.947027412453421e-05, "lambda_grl": 0.20540156702265497, "lambda_domain_loss": 0.20540156702265497, "lambda_domain": 0.20540156702265497, "layer_weights": [0.11057164520025253, 0.11105787009000778, 0.1065446138381958, 0.10416622459888458, 0.09851337224245071, 0.08945624530315399, 0.07904911041259766, 0.07149207592010498, 0.06651802361011505, 0.06060546636581421, 0.05408291891217232, 0.04794246703386307], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T02:10:29.350370Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=2, train_loss=0.4290, val_eer=0.0338"}
{"timestamp": "2026-02-09T02:10:29.351487Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 3: lambda_grl=0.298399, lambda_domain_loss=0.298399"}
{"timestamp": "2026-02-09T02:22:20.003902Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.0% (12930/25856 samples coded)"}
{"timestamp": "2026-02-09T02:33:37.682086Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.0% (25731/51456 samples coded)"}
{"timestamp": "2026-02-09T02:44:52.910007Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 50.0% (38520/77056 samples coded)"}
{"timestamp": "2026-02-09T02:55:36.509231Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 49.8% (51174/102656 samples coded)"}
{"timestamp": "2026-02-09T03:07:02.355327Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 49.9% (63975/128256 samples coded)"}
{"timestamp": "2026-02-09T03:18:13.839063Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 49.9% (76845/153856 samples coded)"}
{"timestamp": "2026-02-09T03:28:58.139077Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.0% (89683/179456 samples coded)"}
{"timestamp": "2026-02-09T03:29:45.935122Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 3 train: loss=0.6046, task_acc=1.0000"}
{"timestamp": "2026-02-09T03:34:34.527717Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 3 val: loss=0.6910, eer=0.0330, min_dcf=0.3038"}
{"timestamp": "2026-02-09T03:34:34.899594Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "New best eer: 0.0330"}
{"timestamp": "2026-02-09T03:34:34.900435Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 3, "duration_sec": 5045.55, "train": {"loss": 0.6045712323838406, "task_loss": 0.00038332141035895667, "task_acc": 0.9999835410814607, "codec_loss": 0.6139590763225314, "codec_q_loss": 1.410802878355712, "codec_acc": 0.7266393082865169, "codec_q_acc": 0.1520968662219101, "aug_rate": 0.4994019926264045, "grad_norm_mean": 0.9513450059992443, "grad_norm_max": 3.048507019825889, "grad_clips": 274, "nan_grads": 0}, "is_best": true, "val": {"loss": 0.6909743085530622, "task_loss": 0.6909743085530622, "task_acc": 0.7874955573878141, "eer": 0.03303235543058769, "min_dcf": 0.3038222479985185}, "learning_rate": 9.891092468409455e-05, "lambda_grl": 0.2983994863270749, "lambda_domain_loss": 0.2983994863270749, "lambda_domain": 0.2983994863270749, "layer_weights": [0.09952402859926224, 0.1076495349407196, 0.101507268846035, 0.10630115121603012, 0.10243210196495056, 0.09237536042928696, 0.08109362423419952, 0.07368821650743484, 0.06936231255531311, 0.0629514828324318, 0.054606810212135315, 0.04850815609097481], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T03:34:34.900739Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=3, train_loss=0.6046, val_eer=0.0330"}
{"timestamp": "2026-02-09T03:34:34.902023Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 4: lambda_grl=0.386149, lambda_domain_loss=0.386149"}
{"timestamp": "2026-02-09T03:46:30.909277Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.4% (13027/25856 samples coded)"}
{"timestamp": "2026-02-09T03:57:43.436776Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.3% (25902/51456 samples coded)"}
{"timestamp": "2026-02-09T04:08:50.583861Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 50.2% (38648/77056 samples coded)"}
{"timestamp": "2026-02-09T04:19:51.499809Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.2% (51529/102656 samples coded)"}
{"timestamp": "2026-02-09T04:31:24.284275Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.2% (64401/128256 samples coded)"}
{"timestamp": "2026-02-09T04:42:27.509784Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.3% (77392/153856 samples coded)"}
{"timestamp": "2026-02-09T04:53:27.688893Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.2% (90093/179456 samples coded)"}
{"timestamp": "2026-02-09T04:54:20.927012Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 4 train: loss=0.7723, task_acc=1.0000"}
{"timestamp": "2026-02-09T04:59:12.440190Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 4 val: loss=0.7209, eer=0.0331, min_dcf=0.3000"}
{"timestamp": "2026-02-09T04:59:12.470300Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 4, "duration_sec": 5077.57, "train": {"loss": 0.7723194164004219, "task_loss": 0.0002762633899038427, "task_acc": 0.9999780547752809, "codec_loss": 0.5982387115278941, "codec_q_loss": 1.4010989038127193, "codec_acc": 0.731395935744382, "codec_q_acc": 0.15242604459269662, "aug_rate": 0.5020463922050562, "grad_norm_mean": 1.3674663681391928, "grad_norm_max": 5.397803035034525, "grad_clips": 425, "nan_grads": 0}, "is_best": false, "val": {"loss": 0.7209299623749866, "task_loss": 0.7209299623749866, "task_acc": 0.7915698730145089, "eer": 0.033061996671586394, "min_dcf": 0.3000060042371978}, "learning_rate": 9.815503934173465e-05, "lambda_grl": 0.38614947263267274, "lambda_domain_loss": 0.38614947263267274, "lambda_domain": 0.38614947263267274, "layer_weights": [0.09010859578847885, 0.1039222776889801, 0.09496112912893295, 0.10829254984855652, 0.10567856580018997, 0.09477020055055618, 0.08277100324630737, 0.07599862664937973, 0.07295983284711838, 0.0659119188785553, 0.05532841011881828, 0.04929686710238457], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T04:59:12.470578Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=4, train_loss=0.7723, val_eer=0.0331"}
{"timestamp": "2026-02-09T04:59:12.471685Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 5: lambda_grl=0.467496, lambda_domain_loss=0.467496"}
{"timestamp": "2026-02-09T05:11:02.526592Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.3% (13001/25856 samples coded)"}
{"timestamp": "2026-02-09T05:22:40.702502Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.1% (25795/51456 samples coded)"}
{"timestamp": "2026-02-09T05:33:20.520892Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 50.1% (38591/77056 samples coded)"}
{"timestamp": "2026-02-09T05:44:53.655075Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 49.9% (51231/102656 samples coded)"}
{"timestamp": "2026-02-09T05:50:06.104647Z", "level": "WARNING", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Non-finite gradients detected at batch 448 (global_step=4008, grad_norm=inf). params=['domain_discriminator.shared.0.weight'] sample_ids=[{'flac_file': 'T_0000019293', 'codec_seed': '-', 'speaker_id': 'T_4362'}, {'flac_file': 'T_0000015632', 'codec_seed': '-', 'speaker_id': 'T_1737'}, {'flac_file': 'T_0000171727', 'codec_seed': '-', 'speaker_id': 'T_3996'}, {'flac_file': 'T_0000019566', 'codec_seed': '-', 'speaker_id': 'T_0046'}, {'flac_file': 'T_0000100797', 'codec_seed': '-', 'speaker_id': 'T_3828'}] waveform_stats={'min': -0.732513, 'max': 0.74585, 'mean': -0.000360958} repr_stats={'min': -1.6796875, 'max': 1.59375, 'mean': -0.03872183710336685}"}
{"timestamp": "2026-02-09T05:50:06.105501Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[non_finite_grad_batch]", "event_type": "non_finite_grad_batch", "data": {"batch_idx": 448, "global_step": 4008, "method": "dann", "grad_norm": null, "clipped_grad_norm": Infinity, "params": ["domain_discriminator.shared.0.weight"], "sample_ids": [{"flac_file": "T_0000019293", "codec_seed": "-", "speaker_id": "T_4362"}, {"flac_file": "T_0000015632", "codec_seed": "-", "speaker_id": "T_1737"}, {"flac_file": "T_0000171727", "codec_seed": "-", "speaker_id": "T_3996"}, {"flac_file": "T_0000019566", "codec_seed": "-", "speaker_id": "T_0046"}, {"flac_file": "T_0000100797", "codec_seed": "-", "speaker_id": "T_3828"}], "waveform_stats": {"min": -0.732513427734375, "max": 0.745849609375, "mean": -0.00036095810355618596}, "repr_stats": {"min": -1.6796875, "max": 1.59375, "mean": -0.03872183710336685}, "losses": {"total_loss": 0.9561428427696228, "task_loss": 2.6837922632694244e-05, "codec_loss": 0.6802653074264526, "codec_q_loss": 1.3649202585220337}}}
{"timestamp": "2026-02-09T05:50:06.122594Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[non_finite_grad_batch] {\"event_type\": \"non_finite_grad_batch\", \"run_id\": \"wavlm_dann\", \"timestamp\": \"2026-02-09T05:50:06.105222Z\", \"batch_idx\": 448, \"global_step\": 4008, \"method\": \"dann\", \"grad_norm\": null, \"clipped_grad_no"}
{"timestamp": "2026-02-09T05:55:22.283401Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 49.9% (64031/128256 samples coded)"}
{"timestamp": "2026-02-09T06:07:07.650696Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 49.9% (76788/153856 samples coded)"}
{"timestamp": "2026-02-09T06:17:55.969487Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 49.9% (89633/179456 samples coded)"}
{"timestamp": "2026-02-09T06:19:17.394294Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 5 train: loss=0.9319, task_acc=0.9999"}
{"timestamp": "2026-02-09T06:24:06.017118Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 5 val: loss=0.9235, eer=0.0334, min_dcf=0.2914"}
{"timestamp": "2026-02-09T06:24:06.031509Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 5, "duration_sec": 5093.56, "train": {"loss": 0.9319152067718881, "task_loss": 0.00024758018173926167, "task_acc": 0.9999451369382022, "codec_loss": 0.5966562695298971, "codec_q_loss": 1.3962328043881427, "codec_acc": 0.7305345856741573, "codec_q_acc": 0.15346295646067415, "aug_rate": 0.4996653353230337, "grad_norm_mean": Infinity, "grad_norm_max": Infinity, "grad_clips": 588, "nan_grads": 1}, "is_best": false, "val": {"loss": 0.9234913639494382, "task_loss": 0.9234913639494382, "task_acc": 0.7540328191109881, "eer": 0.03335157473007985, "min_dcf": 0.29144391214905063}, "per_codec": {"NONE": {"eer": 0.03335157473007985, "n_samples": 140950}}, "per_codec_q": {"NONE": {"eer": 0.03335157473007985, "n_samples": 140950}}, "learning_rate": 9.720715411908369e-05, "lambda_grl": 0.4674959856874097, "lambda_domain_loss": 0.4674959856874097, "lambda_domain": 0.4674959856874097, "layer_weights": [0.08240330964326859, 0.1003745049238205, 0.08805299550294876, 0.10906053334474564, 0.10848368704319, 0.09709025919437408, 0.08445736020803452, 0.07835065573453903, 0.07652905583381653, 0.0687352642416954, 0.056284453719854355, 0.050177957862615585], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T06:24:06.031790Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=5, train_loss=0.9319, val_eer=0.0334"}
{"timestamp": "2026-02-09T06:24:06.396272Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 6: lambda_grl=0.541679, lambda_domain_loss=0.541679"}
{"timestamp": "2026-02-09T06:36:10.262338Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.2% (12992/25856 samples coded)"}
{"timestamp": "2026-02-09T06:47:05.617338Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.2% (25814/51456 samples coded)"}
{"timestamp": "2026-02-09T06:58:38.934358Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 50.1% (38624/77056 samples coded)"}
{"timestamp": "2026-02-09T07:09:28.956531Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.1% (51474/102656 samples coded)"}
{"timestamp": "2026-02-09T07:21:04.747575Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.1% (64230/128256 samples coded)"}
{"timestamp": "2026-02-09T07:32:09.348505Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.1% (77142/153856 samples coded)"}
{"timestamp": "2026-02-09T07:43:39.637102Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.1% (89987/179456 samples coded)"}
{"timestamp": "2026-02-09T07:44:28.738754Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 6 train: loss=1.0787, task_acc=1.0000"}
{"timestamp": "2026-02-09T07:49:18.526447Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 6 val: loss=1.3368, eer=0.0314, min_dcf=0.2778"}
{"timestamp": "2026-02-09T07:49:18.949037Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "New best eer: 0.0314"}
{"timestamp": "2026-02-09T07:49:18.949799Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 6, "duration_sec": 5112.55, "train": {"loss": 1.0786830532584297, "task_loss": 0.0001366223232150915, "task_acc": 0.9999945136938202, "codec_loss": 0.5957211173568548, "codec_q_loss": 1.3953958744748254, "codec_acc": 0.7306443117977528, "codec_q_acc": 0.1539841555477528, "aug_rate": 0.5015690835674157, "grad_norm_mean": 2.5476855497901734, "grad_norm_max": 9.662477337471103, "grad_clips": 662, "nan_grads": 0}, "is_best": true, "val": {"loss": 1.336787558186076, "task_loss": 1.336787558186076, "task_acc": 0.6848295712860439, "eer": 0.03143625893312686, "min_dcf": 0.27781448411932186}, "learning_rate": 9.60684517462142e-05, "lambda_grl": 0.5416790713280547, "lambda_domain_loss": 0.5416790713280547, "lambda_domain": 0.5416790713280547, "layer_weights": [0.07566410303115845, 0.09675665199756622, 0.08147844672203064, 0.1085059642791748, 0.11087941378355026, 0.09928752481937408, 0.08613286167383194, 0.08080056309700012, 0.08029918372631073, 0.071660615503788, 0.057381756603717804, 0.05115285515785217], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T07:49:18.950085Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=6, train_loss=1.0787, val_eer=0.0314"}
{"timestamp": "2026-02-09T07:49:18.951440Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 7: lambda_grl=0.608324, lambda_domain_loss=0.608324"}
{"timestamp": "2026-02-09T08:01:18.289291Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.3% (13006/25856 samples coded)"}
{"timestamp": "2026-02-09T08:12:41.462017Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.2% (25824/51456 samples coded)"}
{"timestamp": "2026-02-09T08:18:41.371898Z", "level": "WARNING", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Non-finite gradients detected at batch 255 (global_step=5239, grad_norm=inf). params=['domain_discriminator.shared.0.weight'] sample_ids=[{'flac_file': 'T_0000010375', 'codec_seed': '-', 'speaker_id': 'T_0636'}, {'flac_file': 'T_0000142192', 'codec_seed': '-', 'speaker_id': 'T_4305'}, {'flac_file': 'T_0000099350', 'codec_seed': '-', 'speaker_id': 'T_2150'}, {'flac_file': 'T_0000004153', 'codec_seed': '-', 'speaker_id': 'T_2578'}, {'flac_file': 'T_0000031442', 'codec_seed': '-', 'speaker_id': 'T_4787'}] waveform_stats={'min': -0.653229, 'max': 0.908752, 'mean': 5.73466e-06} repr_stats={'min': -1.8759765625, 'max': 1.8017578125, 'mean': -0.041491590440273285}"}
{"timestamp": "2026-02-09T08:18:41.392083Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[non_finite_grad_batch]", "event_type": "non_finite_grad_batch", "data": {"batch_idx": 255, "global_step": 5239, "method": "dann", "grad_norm": null, "clipped_grad_norm": Infinity, "params": ["domain_discriminator.shared.0.weight"], "sample_ids": [{"flac_file": "T_0000010375", "codec_seed": "-", "speaker_id": "T_0636"}, {"flac_file": "T_0000142192", "codec_seed": "-", "speaker_id": "T_4305"}, {"flac_file": "T_0000099350", "codec_seed": "-", "speaker_id": "T_2150"}, {"flac_file": "T_0000004153", "codec_seed": "-", "speaker_id": "T_2578"}, {"flac_file": "T_0000031442", "codec_seed": "-", "speaker_id": "T_4787"}], "waveform_stats": {"min": -0.653228759765625, "max": 0.90875244140625, "mean": 5.734659680456389e-06}, "repr_stats": {"min": -1.8759765625, "max": 1.8017578125, "mean": -0.041491590440273285}, "losses": {"total_loss": 1.2438511848449707, "task_loss": 1.3703946024179459e-05, "codec_loss": 0.6320227384567261, "codec_q_loss": 1.412672519683838}}}
{"timestamp": "2026-02-09T08:18:41.392401Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[non_finite_grad_batch] {\"event_type\": \"non_finite_grad_batch\", \"run_id\": \"wavlm_dann\", \"timestamp\": \"2026-02-09T08:18:41.391827Z\", \"batch_idx\": 255, \"global_step\": 5239, \"method\": \"dann\", \"grad_norm\": null, \"clipped_grad_no"}
{"timestamp": "2026-02-09T08:23:52.283091Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 50.3% (38741/77056 samples coded)"}
{"timestamp": "2026-02-09T08:35:23.525990Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.1% (51463/102656 samples coded)"}
{"timestamp": "2026-02-09T08:46:40.317172Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.0% (64190/128256 samples coded)"}
{"timestamp": "2026-02-09T08:57:54.766031Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.0% (76912/153856 samples coded)"}
{"timestamp": "2026-02-09T09:09:16.446388Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.0% (89732/179456 samples coded)"}
{"timestamp": "2026-02-09T09:10:10.303633Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 7 train: loss=1.2131, task_acc=1.0000"}
{"timestamp": "2026-02-09T09:15:00.163300Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 7 val: loss=1.2822, eer=0.0310, min_dcf=0.2709"}
{"timestamp": "2026-02-09T09:15:00.205496Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 7, "duration_sec": 5141.25, "train": {"loss": 1.213085452827175, "task_loss": 0.00020341344473339367, "task_acc": 0.9999615958567416, "codec_loss": 0.5970833705466115, "codec_q_loss": 1.39672555062878, "codec_acc": 0.7301615168539326, "codec_q_acc": 0.15306794241573032, "aug_rate": 0.5000548630617978, "grad_norm_mean": Infinity, "grad_norm_max": Infinity, "grad_clips": 701, "nan_grads": 1}, "is_best": false, "val": {"loss": 1.2822483405876506, "task_loss": 1.2822483405876506, "task_acc": 0.7005233855515772, "eer": 0.03098479053593679, "min_dcf": 0.27091838122923567}, "learning_rate": 9.474673961402159e-05, "lambda_grl": 0.608324099345992, "lambda_domain_loss": 0.608324099345992, "lambda_domain": 0.608324099345992, "layer_weights": [0.06979251652956009, 0.09310483187437057, 0.07534653693437576, 0.10672079026699066, 0.11331960558891296, 0.10151179879903793, 0.08774831146001816, 0.08328144252300262, 0.0840090736746788, 0.07452705502510071, 0.058498531579971313, 0.052139561623334885], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T09:15:00.246759Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=7, train_loss=1.2131, val_eer=0.0310"}
{"timestamp": "2026-02-09T09:15:00.247997Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 8: lambda_grl=0.667396, lambda_domain_loss=0.667396"}
{"timestamp": "2026-02-09T09:26:53.054869Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 49.8% (12888/25856 samples coded)"}
{"timestamp": "2026-02-09T09:38:49.712262Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.0% (25733/51456 samples coded)"}
{"timestamp": "2026-02-09T09:51:58.528370Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 50.0% (38556/77056 samples coded)"}
{"timestamp": "2026-02-09T10:03:37.316774Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.1% (51412/102656 samples coded)"}
{"timestamp": "2026-02-09T10:14:35.974763Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.1% (64233/128256 samples coded)"}
{"timestamp": "2026-02-09T10:26:05.030038Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.0% (76994/153856 samples coded)"}
{"timestamp": "2026-02-09T10:37:06.104512Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.2% (90014/179456 samples coded)"}
{"timestamp": "2026-02-09T10:37:58.315417Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 8 train: loss=1.3342, task_acc=1.0000"}
{"timestamp": "2026-02-09T10:42:49.060410Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 8 val: loss=0.7105, eer=0.0415, min_dcf=0.3695"}
{"timestamp": "2026-02-09T10:42:49.072214Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 8, "duration_sec": 5268.82, "train": {"loss": 1.3341721678048037, "task_loss": 0.00019598872272632596, "task_acc": 0.9999670821629213, "codec_loss": 0.6037550130335803, "codec_q_loss": 1.3950213180499131, "codec_acc": 0.7269739729634831, "codec_q_acc": 0.15495523174157302, "aug_rate": 0.5016623507724719, "grad_norm_mean": 3.5487989382667777, "grad_norm_max": 12.282513796796556, "grad_clips": 709, "nan_grads": 0}, "is_best": false, "val": {"loss": 0.7105158747540627, "task_loss": 0.7105158747540627, "task_acc": 0.8271056412568759, "eer": 0.04151902741917829, "min_dcf": 0.369468315380489}, "learning_rate": 9.324366689758379e-05, "lambda_grl": 0.6673964025651704, "lambda_domain_loss": 0.6673964025651704, "lambda_domain": 0.6673964025651704, "layer_weights": [0.06456112116575241, 0.08942971378564835, 0.06980482488870621, 0.10402932018041611, 0.11554484814405441, 0.10370950400829315, 0.0892200618982315, 0.08578909933567047, 0.08781279623508453, 0.07736536115407944, 0.05961824208498001, 0.05311506986618042], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T10:42:49.072782Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=8, train_loss=1.3342, val_eer=0.0415"}
{"timestamp": "2026-02-09T10:42:49.073858Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 9: lambda_grl=0.719135, lambda_domain_loss=0.719135"}
{"timestamp": "2026-02-09T10:55:03.018331Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.6% (13072/25856 samples coded)"}
{"timestamp": "2026-02-09T11:06:23.552288Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.3% (25890/51456 samples coded)"}
{"timestamp": "2026-02-09T11:17:11.498529Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 50.2% (38696/77056 samples coded)"}
{"timestamp": "2026-02-09T11:28:46.386975Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.2% (51492/102656 samples coded)"}
{"timestamp": "2026-02-09T11:39:41.194367Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.1% (64238/128256 samples coded)"}
{"timestamp": "2026-02-09T11:51:10.702788Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.1% (77013/153856 samples coded)"}
{"timestamp": "2026-02-09T12:02:06.456474Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.0% (89701/179456 samples coded)"}
{"timestamp": "2026-02-09T12:02:58.199335Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 9 train: loss=1.4448, task_acc=1.0000"}
{"timestamp": "2026-02-09T12:07:51.879831Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 9 val: loss=0.8326, eer=0.0359, min_dcf=0.3215"}
{"timestamp": "2026-02-09T12:07:51.922705Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 9, "duration_sec": 5102.85, "train": {"loss": 1.4447731712226117, "task_loss": 0.00013721305968532904, "task_acc": 0.9999725684691011, "codec_loss": 0.6127633991954702, "codec_q_loss": 1.3960892167988788, "codec_acc": 0.7240168539325843, "codec_q_acc": 0.15341906601123595, "aug_rate": 0.49990124648876405, "grad_norm_mean": 4.231703231918235, "grad_norm_max": 16.51298402458732, "grad_clips": 712, "nan_grads": 0}, "is_best": false, "val": {"loss": 0.8325859273085793, "task_loss": 0.8325859273085793, "task_acc": 0.8049859157923994, "eer": 0.03590076774811615, "min_dcf": 0.32145441484176535}, "learning_rate": 9.156706588810236e-05, "lambda_grl": 0.7191348914970344, "lambda_domain_loss": 0.7191348914970344, "lambda_domain": 0.7191348914970344, "layer_weights": [0.060058098286390305, 0.0859202891588211, 0.06488784402608871, 0.10071614384651184, 0.11761656403541565, 0.10588063299655914, 0.09063202887773514, 0.08821931481361389, 0.09147968888282776, 0.07994836568832397, 0.06060966104269028, 0.0540313757956028], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T12:07:51.922959Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=9, train_loss=1.4448, val_eer=0.0359"}
{"timestamp": "2026-02-09T12:07:51.924058Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 10: lambda_grl=0.763978, lambda_domain_loss=0.763978"}
{"timestamp": "2026-02-09T12:19:42.588160Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 49.4% (12770/25856 samples coded)"}
{"timestamp": "2026-02-09T12:24:28.577932Z", "level": "WARNING", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Non-finite gradients detected at batch 138 (global_step=7258, grad_norm=inf). params=['domain_discriminator.shared.0.weight'] sample_ids=[{'flac_file': 'T_0000104350', 'codec_seed': '-', 'speaker_id': 'T_5124'}, {'flac_file': 'T_0000030246', 'codec_seed': '-', 'speaker_id': 'T_1766'}, {'flac_file': 'T_0000013184', 'codec_seed': '-', 'speaker_id': 'T_2640'}, {'flac_file': 'T_0000158859', 'codec_seed': '-', 'speaker_id': 'T_4618'}, {'flac_file': 'T_0000048673', 'codec_seed': '-', 'speaker_id': 'T_0796'}] waveform_stats={'min': -0.793549, 'max': 0.754547, 'mean': 2.26638e-05} repr_stats={'min': -1.849609375, 'max': 1.8173828125, 'mean': -0.039671920239925385}"}
{"timestamp": "2026-02-09T12:24:28.589619Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[non_finite_grad_batch]", "event_type": "non_finite_grad_batch", "data": {"batch_idx": 138, "global_step": 7258, "method": "dann", "grad_norm": null, "clipped_grad_norm": Infinity, "params": ["domain_discriminator.shared.0.weight"], "sample_ids": [{"flac_file": "T_0000104350", "codec_seed": "-", "speaker_id": "T_5124"}, {"flac_file": "T_0000030246", "codec_seed": "-", "speaker_id": "T_1766"}, {"flac_file": "T_0000013184", "codec_seed": "-", "speaker_id": "T_2640"}, {"flac_file": "T_0000158859", "codec_seed": "-", "speaker_id": "T_4618"}, {"flac_file": "T_0000048673", "codec_seed": "-", "speaker_id": "T_0796"}], "waveform_stats": {"min": -0.793548583984375, "max": 0.754547119140625, "mean": 2.266381125082262e-05}, "repr_stats": {"min": -1.849609375, "max": 1.8173828125, "mean": -0.039671920239925385}, "losses": {"total_loss": 1.519654631614685, "task_loss": 0.0001282491721212864, "codec_loss": 0.5994173288345337, "codec_q_loss": 1.3895481824874878}}}
{"timestamp": "2026-02-09T12:24:28.589890Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[non_finite_grad_batch] {\"event_type\": \"non_finite_grad_batch\", \"run_id\": \"wavlm_dann\", \"timestamp\": \"2026-02-09T12:24:28.589366Z\", \"batch_idx\": 138, \"global_step\": 7258, \"method\": \"dann\", \"grad_norm\": null, \"clipped_grad_no"}
{"timestamp": "2026-02-09T12:31:25.168546Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 49.7% (25565/51456 samples coded)"}
{"timestamp": "2026-02-09T12:42:58.353730Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 49.8% (38412/77056 samples coded)"}
{"timestamp": "2026-02-09T12:54:24.348327Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 49.8% (51115/102656 samples coded)"}
{"timestamp": "2026-02-09T13:05:43.782118Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 49.7% (63747/128256 samples coded)"}
{"timestamp": "2026-02-09T13:16:53.662365Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 49.7% (76528/153856 samples coded)"}
{"timestamp": "2026-02-09T13:28:50.258614Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 49.8% (89372/179456 samples coded)"}
{"timestamp": "2026-02-09T13:29:58.503578Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 10 train: loss=1.5413, task_acc=1.0000"}
{"timestamp": "2026-02-09T13:34:51.469952Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 10 val: loss=2.0239, eer=0.0365, min_dcf=0.3417"}
{"timestamp": "2026-02-09T13:34:51.482681Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 10, "duration_sec": 5219.56, "train": {"loss": 1.541347119413065, "task_loss": 7.678900146856904e-05, "task_acc": 0.9999890273876404, "codec_loss": 0.6211416722181138, "codec_q_loss": 1.3962853252887726, "codec_acc": 0.7195619733146067, "codec_q_acc": 0.15305696980337077, "aug_rate": 0.49812916959269665, "grad_norm_mean": Infinity, "grad_norm_max": Infinity, "grad_clips": 711, "nan_grads": 1}, "is_best": false, "val": {"loss": 2.023887316458022, "task_loss": 2.023887316458022, "task_acc": 0.638386551027073, "eer": 0.03654376772500152, "min_dcf": 0.3417064791175432}, "per_codec": {"NONE": {"eer": 0.03654376772500152, "n_samples": 140950}}, "per_codec_q": {"NONE": {"eer": 0.03654376772500152, "n_samples": 140950}}, "learning_rate": 8.972644558726775e-05, "lambda_grl": 0.763978214396207, "lambda_domain_loss": 0.763978214396207, "lambda_domain": 0.763978214396207, "layer_weights": [0.05603719502687454, 0.08251945674419403, 0.06040611490607262, 0.09664315730333328, 0.11968381702899933, 0.1078815832734108, 0.09197758883237839, 0.09062211215496063, 0.09501979500055313, 0.08250334858894348, 0.061622247099876404, 0.055083561688661575], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T13:34:51.483081Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=10, train_loss=1.5413, val_eer=0.0365"}
{"timestamp": "2026-02-09T13:34:52.004757Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 11: lambda_grl=0.802494, lambda_domain_loss=0.802494"}
{"timestamp": "2026-02-09T13:47:17.737086Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 49.9% (12914/25856 samples coded)"}
{"timestamp": "2026-02-09T13:59:23.159442Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 49.8% (25645/51456 samples coded)"}
{"timestamp": "2026-02-09T14:06:46.127265Z", "level": "WARNING", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Non-finite gradients detected at batch 265 (global_step=8097, grad_norm=inf). params=['domain_discriminator.shared.0.weight'] sample_ids=[{'flac_file': 'T_0000049302', 'codec_seed': '-', 'speaker_id': 'T_3702'}, {'flac_file': 'T_0000025735', 'codec_seed': '-', 'speaker_id': 'T_3191'}, {'flac_file': 'T_0000000968', 'codec_seed': '-', 'speaker_id': 'T_5453'}, {'flac_file': 'T_0000142823', 'codec_seed': '-', 'speaker_id': 'T_1717'}, {'flac_file': 'T_0000005957', 'codec_seed': '-', 'speaker_id': 'T_3734'}] waveform_stats={'min': -0.688446, 'max': 0.731903, 'mean': -1.91343e-05} repr_stats={'min': -1.8212890625, 'max': 1.796875, 'mean': -0.04395569488406181}"}
{"timestamp": "2026-02-09T14:06:46.202902Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[non_finite_grad_batch]", "event_type": "non_finite_grad_batch", "data": {"batch_idx": 265, "global_step": 8097, "method": "dann", "grad_norm": null, "clipped_grad_norm": Infinity, "params": ["domain_discriminator.shared.0.weight"], "sample_ids": [{"flac_file": "T_0000049302", "codec_seed": "-", "speaker_id": "T_3702"}, {"flac_file": "T_0000025735", "codec_seed": "-", "speaker_id": "T_3191"}, {"flac_file": "T_0000000968", "codec_seed": "-", "speaker_id": "T_5453"}, {"flac_file": "T_0000142823", "codec_seed": "-", "speaker_id": "T_1717"}, {"flac_file": "T_0000005957", "codec_seed": "-", "speaker_id": "T_3734"}], "waveform_stats": {"min": -0.688446044921875, "max": 0.731903076171875, "mean": -1.9134276953991503e-05}, "repr_stats": {"min": -1.8212890625, "max": 1.796875, "mean": -0.04395569488406181}, "losses": {"total_loss": 1.7681092023849487, "task_loss": 0.00012794137001037598, "codec_loss": 0.7675380706787109, "codec_q_loss": 1.4355703592300415}}}
{"timestamp": "2026-02-09T14:06:46.203382Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[non_finite_grad_batch] {\"event_type\": \"non_finite_grad_batch\", \"run_id\": \"wavlm_dann\", \"timestamp\": \"2026-02-09T14:06:46.202620Z\", \"batch_idx\": 265, \"global_step\": 8097, \"method\": \"dann\", \"grad_norm\": null, \"clipped_grad_no"}
{"timestamp": "2026-02-09T14:10:29.574749Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 50.0% (38529/77056 samples coded)"}
{"timestamp": "2026-02-09T14:22:17.127590Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.1% (51408/102656 samples coded)"}
{"timestamp": "2026-02-09T14:33:23.909828Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.0% (64068/128256 samples coded)"}
{"timestamp": "2026-02-09T14:45:31.448211Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.0% (76868/153856 samples coded)"}
{"timestamp": "2026-02-09T14:57:00.184552Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.0% (89640/179456 samples coded)"}
{"timestamp": "2026-02-09T14:58:11.947897Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 11 train: loss=1.6340, task_acc=0.9999"}
{"timestamp": "2026-02-09T15:02:59.641495Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 11 val: loss=0.8059, eer=0.0594, min_dcf=0.4983"}
{"timestamp": "2026-02-09T15:02:59.652395Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 11, "duration_sec": 5287.65, "train": {"loss": 1.6340311949842432, "task_loss": 0.00022527288574871889, "task_acc": 0.9999341643258427, "codec_loss": 0.6344141553292114, "codec_q_loss": 1.4014961704444349, "codec_acc": 0.7138562148876404, "codec_q_acc": 0.15271681882022473, "aug_rate": 0.499561095505618, "grad_norm_mean": Infinity, "grad_norm_max": Infinity, "grad_clips": 711, "nan_grads": 1}, "is_best": false, "val": {"loss": 0.805907257834277, "task_loss": 0.805907257834277, "task_acc": 0.8338172073372911, "eer": 0.05939074681283858, "min_dcf": 0.4982987128933436}, "learning_rate": 8.772702287163964e-05, "lambda_grl": 0.8024940315430233, "lambda_domain_loss": 0.8024940315430233, "lambda_domain": 0.8024940315430233, "layer_weights": [0.052425045520067215, 0.07913079857826233, 0.056361518800258636, 0.09206584841012955, 0.12140549719333649, 0.10990144312381744, 0.09323974698781967, 0.09304431080818176, 0.09872186183929443, 0.08511433005332947, 0.06253311038017273, 0.05605646222829819], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T15:02:59.652660Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=11, train_loss=1.6340, val_eer=0.0594"}
{"timestamp": "2026-02-09T15:02:59.653812Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 12: lambda_grl=0.835318, lambda_domain_loss=0.835318"}
{"timestamp": "2026-02-09T15:15:18.511759Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 49.9% (12890/25856 samples coded)"}
{"timestamp": "2026-02-09T15:26:46.064907Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 49.6% (25537/51456 samples coded)"}
{"timestamp": "2026-02-09T15:38:10.638524Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 49.9% (38420/77056 samples coded)"}
{"timestamp": "2026-02-09T15:49:34.973178Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.0% (51342/102656 samples coded)"}
{"timestamp": "2026-02-09T16:01:23.245405Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.1% (64253/128256 samples coded)"}
{"timestamp": "2026-02-09T16:12:13.975172Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.0% (76996/153856 samples coded)"}
{"timestamp": "2026-02-09T16:24:08.717128Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.0% (89791/179456 samples coded)"}
{"timestamp": "2026-02-09T16:25:01.212024Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 12 train: loss=1.7070, task_acc=1.0000"}
{"timestamp": "2026-02-09T16:29:51.007877Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 12 val: loss=1.3668, eer=0.0552, min_dcf=0.5222"}
{"timestamp": "2026-02-09T16:29:51.056986Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 12, "duration_sec": 5211.4, "train": {"loss": 1.707011999541454, "task_loss": 0.00016394838052435538, "task_acc": 0.9999615958567416, "codec_loss": 0.6425099644098389, "codec_q_loss": 1.4008410341953963, "codec_acc": 0.7121554599719101, "codec_q_acc": 0.15404450491573032, "aug_rate": 0.5002029933286517, "grad_norm_mean": 5.998484793555964, "grad_norm_max": 22.481583501015834, "grad_clips": 712, "nan_grads": 0}, "is_best": false, "val": {"loss": 1.3668306631098641, "task_loss": 1.3668306631098641, "task_acc": 0.7538038792930367, "eer": 0.05518161343744302, "min_dcf": 0.5222115666560769}, "learning_rate": 8.557376590011112e-05, "lambda_grl": 0.8353180609420338, "lambda_domain_loss": 0.8353180609420338, "lambda_domain": 0.8353180609420338, "layer_weights": [0.04903217777609825, 0.07570584863424301, 0.05259963497519493, 0.08714248985052109, 0.1228494718670845, 0.11178561300039291, 0.0944923460483551, 0.0955890342593193, 0.10252713412046432, 0.08769948780536652, 0.06341579556465149, 0.05716102570295334], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T16:29:51.057237Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=12, train_loss=1.7070, val_eer=0.0552"}
{"timestamp": "2026-02-09T16:29:51.058308Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 13: lambda_grl=0.863106, lambda_domain_loss=0.863106"}
{"timestamp": "2026-02-09T16:41:50.489895Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.0% (12919/25856 samples coded)"}
{"timestamp": "2026-02-09T16:53:36.105663Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.0% (25731/51456 samples coded)"}
{"timestamp": "2026-02-09T17:04:46.191169Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 49.7% (38331/77056 samples coded)"}
{"timestamp": "2026-02-09T17:16:18.854097Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 49.9% (51241/102656 samples coded)"}
{"timestamp": "2026-02-09T17:27:43.197480Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 49.9% (64046/128256 samples coded)"}
{"timestamp": "2026-02-09T17:38:45.913386Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 49.9% (76824/153856 samples coded)"}
{"timestamp": "2026-02-09T17:50:36.638301Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.0% (89790/179456 samples coded)"}
{"timestamp": "2026-02-09T17:51:30.460483Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 13 train: loss=1.7805, task_acc=1.0000"}
{"timestamp": "2026-02-09T17:56:19.950413Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 13 val: loss=1.2404, eer=0.0490, min_dcf=0.4619"}
{"timestamp": "2026-02-09T17:56:19.961155Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 13, "duration_sec": 5188.9, "train": {"loss": 1.780462885338269, "task_loss": 0.00010974040082289597, "task_acc": 0.9999780547752809, "codec_loss": 0.6551469426309124, "codec_q_loss": 1.4075814391789812, "codec_acc": 0.7043539325842697, "codec_q_acc": 0.15148788623595505, "aug_rate": 0.5001371576544944, "grad_norm_mean": 6.402016053242092, "grad_norm_max": 19.858565711035155, "grad_clips": 712, "nan_grads": 0}, "is_best": false, "val": {"loss": 1.2403841272888945, "task_loss": 1.2403841272888945, "task_acc": 0.7737158765161103, "eer": 0.04898419764939395, "min_dcf": 0.46191826736103225}, "learning_rate": 8.327811846073058e-05, "lambda_grl": 0.8631059277201735, "lambda_domain_loss": 0.8631059277201735, "lambda_domain": 0.8631059277201735, "layer_weights": [0.045920681208372116, 0.07228201627731323, 0.04915260151028633, 0.08235091716051102, 0.12420705705881119, 0.1135580763220787, 0.09567581117153168, 0.09806273132562637, 0.10621413588523865, 0.09012530744075775, 0.06419666111469269, 0.05825398489832878], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T17:56:19.961407Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=13, train_loss=1.7805, val_eer=0.0490"}
{"timestamp": "2026-02-09T17:56:19.962548Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 14: lambda_grl=0.886498, lambda_domain_loss=0.886498"}
{"timestamp": "2026-02-09T18:08:34.712107Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.6% (13083/25856 samples coded)"}
{"timestamp": "2026-02-09T18:12:27.496592Z", "level": "WARNING", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Non-finite gradients detected at batch 133 (global_step=10101, grad_norm=inf). params=['domain_discriminator.shared.0.weight'] sample_ids=[{'flac_file': 'T_0000164325', 'codec_seed': '-', 'speaker_id': 'T_5451'}, {'flac_file': 'T_0000103526', 'codec_seed': '-', 'speaker_id': 'T_0877'}, {'flac_file': 'T_0000040986', 'codec_seed': '-', 'speaker_id': 'T_1872'}, {'flac_file': 'T_0000076380', 'codec_seed': '-', 'speaker_id': 'T_2640'}, {'flac_file': 'T_0000073801', 'codec_seed': '-', 'speaker_id': 'T_2150'}] waveform_stats={'min': -0.885345, 'max': 0.887573, 'mean': -3.23185e-07} repr_stats={'min': -1.9267578125, 'max': 1.8984375, 'mean': -0.04206622764468193}"}
{"timestamp": "2026-02-09T18:12:27.504972Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[non_finite_grad_batch]", "event_type": "non_finite_grad_batch", "data": {"batch_idx": 133, "global_step": 10101, "method": "dann", "grad_norm": null, "clipped_grad_norm": Infinity, "params": ["domain_discriminator.shared.0.weight"], "sample_ids": [{"flac_file": "T_0000164325", "codec_seed": "-", "speaker_id": "T_5451"}, {"flac_file": "T_0000103526", "codec_seed": "-", "speaker_id": "T_0877"}, {"flac_file": "T_0000040986", "codec_seed": "-", "speaker_id": "T_1872"}, {"flac_file": "T_0000076380", "codec_seed": "-", "speaker_id": "T_2640"}, {"flac_file": "T_0000073801", "codec_seed": "-", "speaker_id": "T_2150"}], "waveform_stats": {"min": -0.885345458984375, "max": 0.8875732421875, "mean": -3.231850769225275e-07}, "repr_stats": {"min": -1.9267578125, "max": 1.8984375, "mean": -0.04206622764468193}, "losses": {"total_loss": 1.8284094333648682, "task_loss": 1.1195428669452667e-05, "codec_loss": 0.6961474418640137, "codec_q_loss": 1.3663479089736938}}}
{"timestamp": "2026-02-09T18:12:27.505247Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[non_finite_grad_batch] {\"event_type\": \"non_finite_grad_batch\", \"run_id\": \"wavlm_dann\", \"timestamp\": \"2026-02-09T18:12:27.504744Z\", \"batch_idx\": 133, \"global_step\": 10101, \"method\": \"dann\", \"grad_norm\": null, \"clipped_grad_n"}
{"timestamp": "2026-02-09T18:19:59.192967Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.2% (25812/51456 samples coded)"}
{"timestamp": "2026-02-09T18:31:47.550826Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 50.2% (38672/77056 samples coded)"}
{"timestamp": "2026-02-09T18:43:39.553287Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.1% (51383/102656 samples coded)"}
{"timestamp": "2026-02-09T18:55:33.315195Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.1% (64246/128256 samples coded)"}
{"timestamp": "2026-02-09T19:06:34.803580Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.1% (77045/153856 samples coded)"}
{"timestamp": "2026-02-09T19:18:03.261910Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.0% (89685/179456 samples coded)"}
{"timestamp": "2026-02-09T19:18:58.817908Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 14 train: loss=1.8358, task_acc=1.0000"}
{"timestamp": "2026-02-09T19:23:48.965608Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 14 val: loss=1.1277, eer=0.0526, min_dcf=0.5138"}
{"timestamp": "2026-02-09T19:23:48.977327Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 14, "duration_sec": 5249.01, "train": {"loss": 1.8358127026075728, "task_loss": 0.00014961882902497656, "task_acc": 0.9999615958567416, "codec_loss": 0.6668506481506852, "codec_q_loss": 1.4038396005550127, "codec_acc": 0.6984835849719101, "codec_q_acc": 0.1525193117977528, "aug_rate": 0.49978603405898875, "grad_norm_mean": Infinity, "grad_norm_max": Infinity, "grad_clips": 711, "nan_grads": 1}, "is_best": false, "val": {"loss": 1.127690870402729, "task_loss": 1.127690870402729, "task_acc": 0.7960716311814781, "eer": 0.05259365642260595, "min_dcf": 0.5138353832529164}, "learning_rate": 8.085290018399129e-05, "lambda_grl": 0.88649813172024, "lambda_domain_loss": 0.88649813172024, "lambda_domain": 0.88649813172024, "layer_weights": [0.0430929958820343, 0.06899359077215195, 0.046021781861782074, 0.07773517817258835, 0.12503737211227417, 0.11515684425830841, 0.09679772704839706, 0.10051421076059341, 0.10996617376804352, 0.092446468770504, 0.06489058583974838, 0.05934712290763855], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-09T19:23:48.977585Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=14, train_loss=1.8358, val_eer=0.0526"}
{"timestamp": "2026-02-09T19:23:48.978643Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 15: lambda_grl=0.906097, lambda_domain_loss=0.906097"}
{"timestamp": "2026-02-09T19:35:54.978779Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.2% (12969/25856 samples coded)"}
{"timestamp": "2026-02-09T23:21:37.752640Z", "level": "INFO", "logger": "__main__", "message": "Run directory: /projects/prjs1904/runs/wavlm_dann"}
{"timestamp": "2026-02-09T23:21:39.888111Z", "level": "INFO", "logger": "__main__", "message": "Git commit: aafa40a8"}
{"timestamp": "2026-02-09T23:21:39.888262Z", "level": "INFO", "logger": "__main__", "message": "Hardware: NVIDIA A100-SXM4-40GB"}
{"timestamp": "2026-02-09T23:21:39.925348Z", "level": "INFO", "logger": "__main__", "message": "CODEC classes (manifest): 12"}
{"timestamp": "2026-02-09T23:21:39.925456Z", "level": "INFO", "logger": "__main__", "message": "CODEC_Q classes (manifest): 9"}
{"timestamp": "2026-02-09T23:21:39.982134Z", "level": "INFO", "logger": "__main__", "message": "Using AUGMENTATION_CACHE_DIR from environment: /scratch-shared/jcooper/asvspoof5_augmented_cache"}
{"timestamp": "2026-02-09T23:21:40.178156Z", "level": "WARNING", "logger": "asvspoof5_domain_invariant_cm.data.codec_augment", "message": "Some requested codecs not supported by ffmpeg: {'OPUS'}. Using: ['MP3', 'AAC']"}
{"timestamp": "2026-02-09T23:21:40.178269Z", "level": "INFO", "logger": "__main__", "message": "Codec augmentor initialized: supported_codecs=['MP3', 'AAC'], codec_prob=0.5"}
{"timestamp": "2026-02-09T23:21:41.001996Z", "level": "INFO", "logger": "__main__", "message": "Train samples: 182357"}
{"timestamp": "2026-02-09T23:21:41.002141Z", "level": "INFO", "logger": "__main__", "message": "Val samples: 140950"}
{"timestamp": "2026-02-09T23:21:41.002501Z", "level": "INFO", "logger": "__main__", "message": "DANN with augmentation: domain discriminator sizes num_codecs=3, num_codec_qs=6"}
{"timestamp": "2026-02-09T23:21:41.005950Z", "level": "INFO", "logger": "__main__", "message": "Saved synthetic vocabs to run dir (DANN with augmentation)"}
{"timestamp": "2026-02-09T23:21:44.668741Z", "level": "INFO", "logger": "__main__", "message": "Total parameters: 96,354,951"}
{"timestamp": "2026-02-09T23:21:44.668898Z", "level": "INFO", "logger": "__main__", "message": "Trainable parameters: 1,973,015"}
{"timestamp": "2026-02-09T23:21:49.494315Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "Wandb initialized: https://wandb.ai/mike-cooper-uva/asvspoof5-dann/runs/vhp1qgyn"}
{"timestamp": "2026-02-09T23:21:49.496931Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "Model: 96,354,951 params (1,973,015 trainable)"}
{"timestamp": "2026-02-09T23:21:49.497430Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "Dataset: train=182357, val=140950"}
{"timestamp": "2026-02-09T23:21:49.530165Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[experiment_start]", "event_type": "experiment_start", "data": {"method": "dann", "backbone": "wavlm_base_plus", "max_epochs": 50, "batch_size": 256, "learning_rate": 0.0001, "model": {"total_params": 96354951, "trainable_params": 1973015}, "dataset": {"train_size": 182357, "val_size": 140950}, "dann": {"lambda_init": 0.1, "lambda_schedule": {"enabled": true, "type": "linear", "start": 0.1, "end": 0.75, "warmup_epochs": 3}}}}
{"timestamp": "2026-02-09T23:21:49.530382Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[experiment_start] method=dann, backbone=wavlm_base_plus"}
{"timestamp": "2026-02-09T23:21:49.530623Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Starting training for 50 epochs"}
{"timestamp": "2026-02-09T23:21:49.530823Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Run directory: /projects/prjs1904/runs/wavlm_dann"}
{"timestamp": "2026-02-09T23:21:49.530988Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Model: 96,354,951 params (1,973,015 trainable)"}
{"timestamp": "2026-02-09T23:21:49.531175Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Dataset: train=182357, val=140950"}
{"timestamp": "2026-02-09T23:21:49.536790Z", "level": "INFO", "logger": "__main__", "message": "============================================================"}
{"timestamp": "2026-02-09T23:21:49.536985Z", "level": "INFO", "logger": "__main__", "message": "Training DANN model"}
{"timestamp": "2026-02-09T23:21:49.537187Z", "level": "INFO", "logger": "__main__", "message": "Backbone: wavlm_base_plus"}
{"timestamp": "2026-02-09T23:21:49.553260Z", "level": "INFO", "logger": "__main__", "message": "Seed: 42"}
{"timestamp": "2026-02-09T23:21:49.553478Z", "level": "INFO", "logger": "__main__", "message": "============================================================"}
{"timestamp": "2026-02-09T23:21:49.553706Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 0: lambda_grl=0.000000, lambda_domain_loss=0.000000"}
{"timestamp": "2026-02-09T23:34:24.463252Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 100: cumulative augmentation rate = 50.2% (12988/25856 samples coded)"}
{"timestamp": "2026-02-09T23:46:14.025145Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 200: cumulative augmentation rate = 50.0% (25745/51456 samples coded)"}
{"timestamp": "2026-02-09T23:57:31.366735Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 300: cumulative augmentation rate = 49.9% (38432/77056 samples coded)"}
{"timestamp": "2026-02-10T00:09:58.613047Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 400: cumulative augmentation rate = 50.0% (51356/102656 samples coded)"}
{"timestamp": "2026-02-10T00:21:31.386288Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 500: cumulative augmentation rate = 50.0% (64126/128256 samples coded)"}
{"timestamp": "2026-02-10T00:33:39.195663Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 600: cumulative augmentation rate = 50.1% (77078/153856 samples coded)"}
{"timestamp": "2026-02-10T00:44:52.662774Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Step 700: cumulative augmentation rate = 50.0% (89801/179456 samples coded)"}
{"timestamp": "2026-02-10T00:46:03.132772Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 0 train: loss=0.1949, task_acc=0.9236"}
{"timestamp": "2026-02-10T00:51:09.270341Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 0 val: loss=0.2997, eer=0.0476, min_dcf=0.4385"}
{"timestamp": "2026-02-10T00:51:09.961854Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "New best eer: 0.0476"}
{"timestamp": "2026-02-10T00:51:09.962907Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete]", "event_type": "epoch_complete", "data": {"epoch": 0, "duration_sec": 5360.41, "train": {"loss": 0.19493231153850746, "task_loss": 0.19493231153850746, "task_acc": 0.9235702686095506, "codec_loss": 1.1014607247341885, "codec_q_loss": 1.796833129411333, "codec_acc": 0.24941845154494383, "codec_q_acc": 0.32933198735955055, "aug_rate": 0.5003566099016854, "grad_norm_mean": 0.3069592487557512, "grad_norm_max": 1.2243083734281357, "grad_clips": 129, "nan_grads": 0}, "is_best": true, "val": {"loss": 0.2996566632590147, "task_loss": 0.2996566632590147, "task_acc": 0.879172621751221, "eer": 0.04757963273162842, "min_dcf": 0.4385055231063059}, "per_codec": {"NONE": {"eer": 0.04757963273162842, "n_samples": 140950}}, "per_codec_q": {"NONE": {"eer": 0.04757963273162842, "n_samples": 140950}}, "learning_rate": 9.999108914437816e-05, "lambda_grl": 0.0, "lambda_domain_loss": 0.0, "lambda_domain": 0.0, "layer_weights": [0.12503711879253387, 0.11382104456424713, 0.10825517028570175, 0.10076490789651871, 0.09199954569339752, 0.0848376601934433, 0.07705381512641907, 0.0703379362821579, 0.06531194597482681, 0.059760309755802155, 0.05422237142920494, 0.04859813675284386], "gpu_memory_gb": 0.398}}
{"timestamp": "2026-02-10T00:51:09.963231Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.utils.logging", "message": "[epoch_complete] epoch=0, train_loss=0.1949, val_eer=0.0476"}
{"timestamp": "2026-02-10T00:51:10.331151Z", "level": "INFO", "logger": "asvspoof5_domain_invariant_cm.training.loop", "message": "Epoch 1: lambda_grl=0.000000, lambda_domain_loss=0.000000"}
