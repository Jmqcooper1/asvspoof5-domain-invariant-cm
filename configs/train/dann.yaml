# DANN (Domain-Adversarial Neural Network) Training Configuration

training:
  method: dann
  
  # Optimizer
  optimizer:
    name: adamw
    lr: 1.0e-4
    weight_decay: 0.01
    betas: [0.9, 0.999]
  
  # Scheduler
  scheduler:
    name: cosine
    warmup_steps: 500
    min_lr: 1.0e-6
  
  # Training loop
  max_epochs: 50
  patience: 10  # Early stopping patience
  gradient_clip: 1.0
  
  # Checkpointing
  save_every_n_epochs: 5
  save_best_only: true
  monitor_metric: eer  # eer, min_dcf
  monitor_mode: min

# Loss
loss:
  task:
    name: cross_entropy
    weight: 1.0
    label_smoothing: 0.0
  
  # Domain adversarial losses
  domain:
    codec:
      name: cross_entropy
      weight: 1.0
    codec_q:
      name: cross_entropy
      weight: 1.0

# DANN-specific settings
dann:
  # Adversarial weight (lambda)
  lambda_: 0.1  # Tune this: [0.01, 0.1, 0.5, 1.0]
  
  # Lambda scheduling (optional)
  lambda_schedule:
    enabled: false
    type: linear  # linear, exponential
    start: 0.0
    end: 1.0
    warmup_epochs: 5
  
  # Multi-head domain discriminator
  discriminator:
    shared_dim: 256
    dropout: 0.1
    # Separate heads for CODEC and CODEC_Q

# Logging
logging:
  log_every_n_steps: 50
  val_every_n_epochs: 1
  log_domain_accuracy: true  # Log domain discriminator accuracy

# Reproducibility
seed: 42
deterministic: true
