#!/bin/bash
#SBATCH --partition=gpu_a100
#SBATCH --gpus=1
#SBATCH --job-name=ASV_Download
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=9
#SBATCH --mem=8G
#SBATCH --time=24:00:00
#SBATCH --output=./scripts/jobs/out/%x_%A.out

# =============================================================================
# ASVspoof5 Dataset Download Job
#
# Downloads the full ASVspoof5 dataset from Zenodo using aria2c (resumable).
# Run this BEFORE stage_dataset.job.
#
# Assumptions:
# - ASVSPOOF5_ROOT is set in .env (destination for downloaded files)
# - Network access is available (Snellius login/cpu nodes have internet)
#
# Note: aria2c supports resumable downloads (-c flag), so re-running after
#       disconnection will continue where it left off.
# =============================================================================

set -euo pipefail

module purge
module load 2025

# Navigate to repo root
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
cd "$SCRIPT_DIR/../.."

# Load .env and require ASVSPOOF5_ROOT
# shellcheck disable=SC1091
source scripts/jobs/_job_common.sh
load_and_require_asvspoof5_root

echo "=== ASVspoof5 Download ==="
echo "Destination: $ASVSPOOF5_ROOT"
echo ""

# Ensure destination exists
mkdir -p "$ASVSPOOF5_ROOT"

# Check for download tools
if command -v aria2c >/dev/null 2>&1; then
    echo "Using aria2c (recommended)"
    aria2c --version | head -1
elif command -v wget >/dev/null 2>&1; then
    echo "Using wget (fallback)"
    wget --version | head -1
elif command -v curl >/dev/null 2>&1; then
    echo "Using curl (fallback)"
    curl --version | head -1
else
    echo "ERROR: No download tool available (need aria2c, wget, or curl)" >&2
    exit 1
fi
echo ""

# Download full dataset (resumable)
# --full: all train/dev/eval shards
# --ipv4: force IPv4 (more reliable on some networks)
# --parallel 16: max connections per file (aria2c max)
echo "Starting download..."
bash scripts/download_asvspoof5.sh --full --ipv4 --parallel 16

echo ""
echo "Download complete!"
echo "Next step: sbatch scripts/jobs/stage_dataset.job"
