<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Domain-Adversarial Training for Codec-Robust Speech Deepfake Detection</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/dist/reveal.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/dist/theme/white.css">
    <link href="https://fonts.googleapis.com/css2?family=Source+Serif+4:wght@400;600;700&family=Source+Sans+3:wght@400;500;600&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    <style>
        :root {
            --heading-font: 'Source Serif 4', Georgia, serif;
            --body-font: 'Source Sans 3', -apple-system, sans-serif;
            --mono-font: 'JetBrains Mono', monospace;
            --accent: #1e40af;
            --accent-light: #dbeafe;
            --text-primary: #1e293b;
            --text-secondary: #475569;
            --border: #e2e8f0;
            --surface: #f8fafc;
        }

        .reveal {
            font-family: var(--body-font);
            font-size: 24px;
            color: var(--text-primary);
        }

        .reveal h1, .reveal h2, .reveal h3 {
            font-family: var(--heading-font);
            font-weight: 600;
            color: var(--text-primary);
            text-transform: none;
            letter-spacing: -0.01em;
            line-height: 1.2;
        }

        .reveal h1 { font-size: 2em; margin-bottom: 0.3em; }
        .reveal h2 { font-size: 1.5em; margin-bottom: 0.5em; }
        .reveal h3 { font-size: 1.1em; margin-bottom: 0.4em; color: var(--text-secondary); font-weight: 500; }

        .reveal ul, .reveal ol { text-align: left; }
        .reveal li { margin-bottom: 0.3em; }

        .two-col {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 2em;
            align-items: start;
        }

        .card {
            background: var(--surface);
            border: 1px solid var(--border);
            border-radius: 6px;
            padding: 0.6em 1em;
            margin: 0.4em 0;
            text-align: left;
        }

        .card-accent {
            background: var(--accent-light);
            border-left: 3px solid var(--accent);
        }

        .card-green {
            background: #dcfce7;
            border-left: 3px solid #16a34a;
        }

        table.data {
            width: 100%;
            border-collapse: collapse;
            font-size: 0.75em;
            margin: 0.5em 0;
        }

        table.data th, table.data td {
            border: 1px solid var(--border);
            padding: 0.4em 0.6em;
            text-align: left;
        }

        table.data th {
            background: var(--surface);
            font-weight: 600;
        }

        table.data tr.highlight {
            background: #dbeafe;
            font-weight: 600;
        }

        .tag {
            display: inline-block;
            font-size: 0.7em;
            font-weight: 600;
            padding: 0.15em 0.5em;
            border-radius: 3px;
            vertical-align: middle;
        }

        .tag-green { background: #dcfce7; color: #166534; }
        .tag-amber { background: #fef3c7; color: #92400e; }
        .tag-blue { background: #dbeafe; color: #1e40af; }
        .tag-red { background: #fee2e2; color: #991b1b; }

        .formula {
            font-family: var(--mono-font);
            font-size: 0.85em;
            background: var(--surface);
            padding: 0.3em 0.6em;
            border-radius: 4px;
            display: inline-block;
        }

        .flow-diagram {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 0.3em;
            margin: 0.5em auto;
        }

        .flow-box {
            padding: 0.4em 1em;
            border-radius: 6px;
            font-size: 0.75em;
            font-weight: 500;
            text-align: center;
            min-width: 180px;
        }

        .flow-box.blue { background: #dbeafe; border: 2px solid #3b82f6; }
        .flow-box.green { background: #dcfce7; border: 2px solid #22c55e; }
        .flow-box.orange { background: #fed7aa; border: 2px solid #f97316; }
        .flow-box.purple { background: #e9d5ff; border: 2px solid #a855f7; }
        .flow-box.gray { background: #f1f5f9; border: 2px solid #94a3b8; }
        .flow-box.red { background: #fee2e2; border: 2px solid #ef4444; }

        .flow-arrow { color: #64748b; font-size: 1.2em; }

        .flow-split {
            display: flex;
            gap: 2em;
            justify-content: center;
        }

        .flow-branch {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 0.3em;
        }

        .small { font-size: 0.8em; color: var(--text-secondary); }
        .smaller { font-size: 0.7em; color: var(--text-secondary); }

        .rq-box {
            background: var(--accent-light);
            border-left: 4px solid var(--accent);
            padding: 0.8em 1em;
            margin: 0.5em 0;
            font-style: italic;
            text-align: left;
        }

        .figure-container {
            text-align: center;
            margin: 0.5em 0;
        }

        .figure-container img {
            max-width: 100%;
            max-height: 420px;
            border: 1px solid var(--border);
            border-radius: 6px;
        }

        .figure-caption {
            font-size: 0.7em;
            color: var(--text-secondary);
            margin-top: 0.3em;
        }

        .metric-box {
            display: inline-block;
            padding: 0.5em 1em;
            margin: 0.3em;
            border-radius: 8px;
            text-align: center;
        }

        .metric-box .value {
            font-size: 1.8em;
            font-weight: 700;
            display: block;
        }

        .metric-box .label {
            font-size: 0.7em;
            color: var(--text-secondary);
        }

        .metric-box.green { background: #dcfce7; }
        .metric-box.blue { background: #dbeafe; }
        .metric-box.amber { background: #fef3c7; }

        .checklist {
            list-style: none;
            margin-left: 0;
            padding-left: 0;
            text-align: left;
        }

        .checklist li {
            padding-left: 1.5em;
            position: relative;
            margin-bottom: 0.4em;
        }

        .checklist li::before {
            position: absolute;
            left: 0;
            font-weight: 600;
        }

        .checklist li.done::before { content: "✓"; color: #16a34a; }
        .checklist li.no::before { content: "✗"; color: #dc2626; }

        blockquote {
            border-left: 4px solid var(--accent);
            padding-left: 1em;
            margin-left: 0;
            font-style: italic;
            color: var(--text-secondary);
        }
    </style>
</head>
<body>
    <div class="reveal">
        <div class="slides">

            <!-- Title Slide -->
            <section style="display: flex; flex-direction: column; justify-content: center; height: 100%;">
                <h1 style="font-size: 1.8em;">Domain-Adversarial Training for<br>Codec-Robust Speech Deepfake Detection</h1>
                <h3 style="font-weight: 400; margin-top: 0.5em;">MSc Artificial Intelligence Thesis</h3>
                <p style="margin-top: 2.5em; color: var(--text-secondary);">
                    Mike Cooper<br>
                    <span class="small">University of Amsterdam · February 2026</span>
                </p>
            </section>

            <!-- Research Question -->
            <section>
                <h2>Research Question</h2>
                <div class="rq-box" style="font-size: 1.2em; margin-top: 1em;">
                    Can domain-adversarial training (DANN) improve generalization of speech deepfake detectors to unseen transmission codecs?
                </div>
                <div style="margin-top: 1.5em;">
                    <h3>Sub-questions</h3>
                    <ol style="font-size: 0.9em;">
                        <li><strong>RQ1:</strong> Does DANN reduce the out-of-domain (OOD) gap?</li>
                        <li><strong>RQ2:</strong> Does DANN improve per-codec performance?</li>
                        <li><strong>RQ3:</strong> Where is domain information removed?</li>
                        <li><strong>RQ4:</strong> What components cause domain invariance?</li>
                    </ol>
                </div>
            </section>

            <!-- Problem: Codec Mismatch -->
            <section>
                <h2>The Problem: Codec Mismatch</h2>
                <div class="two-col">
                    <div>
                        <h3>Training Data</h3>
                        <ul>
                            <li>Clean, uncompressed audio</li>
                            <li>No codec diversity</li>
                            <li>Lab conditions</li>
                        </ul>
                        <h3 style="margin-top: 1em;">Real World</h3>
                        <ul>
                            <li>Compressed (MP3, AAC, Opus)</li>
                            <li>Voice calls (AMR, Speex)</li>
                            <li>Neural codecs (Encodec)</li>
                        </ul>
                    </div>
                    <div>
                        <div class="card" style="margin-top: 0.5em;">
                            <strong>ASVspoof 5 Dataset</strong>
                            <table class="data" style="margin-top: 0.5em;">
                                <tr><th>Split</th><th>Codec Diversity</th></tr>
                                <tr><td>Train</td><td>0% (all uncoded)</td></tr>
                                <tr><td>Dev</td><td>0% (all uncoded)</td></tr>
                                <tr><td>Eval</td><td>75% coded (11 codecs)</td></tr>
                            </table>
                        </div>
                        <div class="card-accent card" style="margin-top: 0.8em;">
                            Detectors overfit to codec-free artifacts → fail on compressed audio
                        </div>
                    </div>
                </div>
            </section>

            <!-- Solution: DANN -->
            <section>
                <h2>Solution: Domain-Adversarial Training</h2>
                <div class="flow-diagram" style="margin-top: 0.5em;">
                    <div class="flow-box gray">Audio Waveform</div>
                    <div class="flow-arrow">↓</div>
                    <div class="flow-box blue">SSL Backbone (WavLM / W2V2)<br><span class="smaller">Frozen</span></div>
                    <div class="flow-arrow">↓</div>
                    <div class="flow-box green">Projection Head<br><span class="smaller">Learnable · 256-dim</span></div>
                    <div class="flow-arrow">↓</div>
                    <div class="flow-split">
                        <div class="flow-branch">
                            <div class="flow-box orange">Task Classifier</div>
                            <div class="flow-arrow">↓</div>
                            <div class="small"><strong>Bonafide / Spoof</strong></div>
                        </div>
                        <div class="flow-branch">
                            <div class="flow-box red">GRL</div>
                            <div class="flow-arrow">↓</div>
                            <div class="flow-box purple">Domain Discriminator</div>
                            <div class="flow-arrow">↓</div>
                            <div class="small"><strong>Codec Label</strong></div>
                        </div>
                    </div>
                </div>
                <p class="small" style="text-align: center; margin-top: 0.5em;">
                    <strong>GRL:</strong> Gradient Reversal Layer — forces encoder to <em>unlearn</em> codec information
                </p>
            </section>

            <!-- Synthetic Augmentation -->
            <section>
                <h2>Synthetic Codec Augmentation</h2>
                <div class="two-col">
                    <div>
                        <h3>Why?</h3>
                        <p>Train/dev have <strong>no codec diversity</strong> — DANN needs domain labels to learn from.</p>
                        
                        <h3 style="margin-top: 1em;">How?</h3>
                        <p>Apply synthetic codecs via ffmpeg during training:</p>
                        <ul style="font-size: 0.9em;">
                            <li>MP3 (64-320 kbps)</li>
                            <li>AAC (32-256 kbps)</li>
                        </ul>
                    </div>
                    <div>
                        <div class="card">
                            <strong>Training Distribution</strong>
                            <ul style="font-size: 0.85em; margin-top: 0.5em;">
                                <li>50% original (uncoded)</li>
                                <li>25% MP3</li>
                                <li>25% AAC</li>
                            </ul>
                        </div>
                        <div class="card-accent card" style="margin-top: 0.8em;">
                            <strong>Key insight:</strong> Even with only 2 synthetic codecs, DANN achieves significant OOD improvement
                        </div>
                    </div>
                </div>
            </section>

            <!-- Main Results -->
            <section>
                <h2>Main Results</h2>
                <table class="data">
                    <tr>
                        <th>Model</th>
                        <th>Backbone</th>
                        <th>Dev EER</th>
                        <th>Eval EER</th>
                        <th>OOD Gap</th>
                        <th>minDCF</th>
                    </tr>
                    <tr>
                        <td>ERM</td>
                        <td>WavLM</td>
                        <td>3.26%</td>
                        <td>8.47%</td>
                        <td>+160%</td>
                        <td>0.639</td>
                    </tr>
                    <tr>
                        <td>ERM+Aug</td>
                        <td>WavLM</td>
                        <td>3.26%</td>
                        <td>8.47%</td>
                        <td>+160%</td>
                        <td>0.639</td>
                    </tr>
                    <tr class="highlight">
                        <td><strong>DANN</strong></td>
                        <td><strong>WavLM</strong></td>
                        <td><strong>4.76%</strong></td>
                        <td><strong>7.34%</strong></td>
                        <td><strong>+54%</strong></td>
                        <td><strong>0.585</strong></td>
                    </tr>
                    <tr>
                        <td>ERM</td>
                        <td>W2V2</td>
                        <td>4.24%</td>
                        <td>15.30%</td>
                        <td>+261%</td>
                        <td>1.000</td>
                    </tr>
                    <tr>
                        <td>DANN</td>
                        <td>W2V2</td>
                        <td>4.45%</td>
                        <td>14.33%</td>
                        <td>+222%</td>
                        <td>1.000</td>
                    </tr>
                </table>
                <div style="margin-top: 0.8em; text-align: center;">
                    <div class="metric-box green">
                        <span class="value">66%</span>
                        <span class="label">OOD Gap Reduction</span>
                    </div>
                    <div class="metric-box blue">
                        <span class="value">7.34%</span>
                        <span class="label">Best Eval EER</span>
                    </div>
                </div>
            </section>

            <!-- RQ1: OOD Gap -->
            <section>
                <h2>RQ1: Does DANN Reduce the OOD Gap?</h2>
                <div class="card-green card" style="font-size: 1.1em; margin-bottom: 0.8em;">
                    <strong>✓ Yes.</strong> WavLM OOD gap reduced from 160% to 54% (66% relative reduction)
                </div>
                <div class="figure-container">
                    <img src="../../figures/ood_gap.png" alt="OOD Gap Comparison">
                    <div class="figure-caption">Figure: OOD gap (Eval EER − Dev EER) for ERM vs DANN</div>
                </div>
            </section>

            <!-- RQ1 continued: Detailed Tables -->
            <section>
                <h2>RQ1: Detailed Results Tables</h2>
                <div class="two-col" style="gap: 1.5em; align-items: start;">
                    <div>
                        <h3>Table 1: Main Results</h3>
                        <table class="data" style="font-size: 0.65em;">
                            <tr>
                                <th>Model</th>
                                <th>Backbone</th>
                                <th>Dev EER</th>
                                <th>Eval EER</th>
                                <th>minDCF</th>
                            </tr>
                            <tr>
                                <td>ERM</td>
                                <td>WavLM</td>
                                <td>3.26%</td>
                                <td>8.47%</td>
                                <td>0.639</td>
                            </tr>
                            <tr class="highlight">
                                <td><strong>DANN</strong></td>
                                <td><strong>WavLM</strong></td>
                                <td><strong>4.76%</strong></td>
                                <td><strong>7.34%</strong></td>
                                <td><strong>0.585</strong></td>
                            </tr>
                            <tr>
                                <td>ERM</td>
                                <td>W2V2</td>
                                <td>4.24%</td>
                                <td>15.30%</td>
                                <td>1.000</td>
                            </tr>
                            <tr>
                                <td>DANN</td>
                                <td>W2V2</td>
                                <td>4.45%</td>
                                <td>14.33%</td>
                                <td>1.000</td>
                            </tr>
                            <tr>
                                <td>LFCC-GMM</td>
                                <td>LFCC</td>
                                <td>17.59%</td>
                                <td>43.33%</td>
                                <td>0.999</td>
                            </tr>
                            <tr>
                                <td>TRILLsson Log</td>
                                <td>TRILLsson</td>
                                <td>19.35%</td>
                                <td>23.75%</td>
                                <td>1.000</td>
                            </tr>
                            <tr>
                                <td>TRILLsson MLP</td>
                                <td>TRILLsson</td>
                                <td>20.32%</td>
                                <td>25.65%</td>
                                <td>1.000</td>
                            </tr>
                        </table>
                    </div>
                    <div>
                        <h3>Table 2: Per-Codec EER (%)</h3>
                        <table class="data" style="font-size: 0.6em;">
                            <tr>
                                <th>Codec</th>
                                <th>WavLM ERM</th>
                                <th>WavLM DANN</th>
                                <th>Δ</th>
                            </tr>
                            <tr><td>NONE</td><td>5.68</td><td><strong>4.19</strong></td><td class="small" style="color:#16a34a;">−26%</td></tr>
                            <tr><td>C01 (opus)</td><td>7.49</td><td><strong>6.63</strong></td><td class="small" style="color:#16a34a;">−11%</td></tr>
                            <tr><td>C02 (amr)</td><td>5.88</td><td><strong>5.27</strong></td><td class="small" style="color:#16a34a;">−10%</td></tr>
                            <tr><td>C03 (speex)</td><td>7.90</td><td><strong>6.88</strong></td><td class="small" style="color:#16a34a;">−13%</td></tr>
                            <tr><td>C04 (encodec)</td><td>10.68</td><td><strong>9.32</strong></td><td class="small" style="color:#16a34a;">−13%</td></tr>
                            <tr><td>C05 (mp3)</td><td>6.09</td><td><strong>4.54</strong></td><td class="small" style="color:#16a34a;">−25%</td></tr>
                            <tr><td>C06 (m4a)</td><td>6.85</td><td><strong>5.43</strong></td><td class="small" style="color:#16a34a;">−21%</td></tr>
                            <tr><td>C07 (mp3+enc)</td><td>12.50</td><td><strong>11.16</strong></td><td class="small" style="color:#16a34a;">−11%</td></tr>
                            <tr><td>C08 (opus_nb)</td><td>10.22</td><td><strong>9.66</strong></td><td class="small" style="color:#16a34a;">−5%</td></tr>
                            <tr><td>C09 (amr_nb)</td><td>9.97</td><td><strong>9.10</strong></td><td class="small" style="color:#16a34a;">−9%</td></tr>
                            <tr><td>C10 (speex_nb)</td><td>10.90</td><td><strong>10.37</strong></td><td class="small" style="color:#16a34a;">−5%</td></tr>
                            <tr><td>C11 (device)</td><td>8.19</td><td><strong>6.85</strong></td><td class="small" style="color:#16a34a;">−16%</td></tr>
                        </table>
                    </div>
                </div>
                <p class="small" style="text-align: center; margin-top: 0.5em;">
                    DANN improves on <strong>all codecs</strong>, including uncovered ones (C04, C07, C11)
                </p>
            </section>

            <!-- RQ2: Per-Codec -->
            <section>
                <h2>RQ2: Does DANN Improve Per-Codec Performance?</h2>
                <div class="card-green card" style="font-size: 1.1em; margin-bottom: 0.8em;">
                    <strong>✓ Yes.</strong> Improvement observed across all codecs in the evaluation set
                </div>
                <div class="figure-container">
                    <img src="../../figures/per_codec_eer.png" alt="Per-Codec EER">
                    <div class="figure-caption">Figure: Per-codec EER comparison (WavLM ERM vs DANN)</div>
                </div>
            </section>

            <!-- RQ3: Where is domain info removed? -->
            <section>
                <h2>RQ3: Where is Domain Information Removed?</h2>
                <div class="card-green card" style="font-size: 1.1em; margin-bottom: 0.8em;">
                    <strong>✓ Projection layer.</strong> Codec probe accuracy drops 43.4% → 38.8%
                </div>
                <div class="figure-container">
                    <img src="../../figures/rq3_combined.png" alt="Domain Probing Results">
                    <div class="figure-caption">Figure: Layer-wise codec probe accuracy (ERM vs DANN)</div>
                </div>
                <p class="small" style="text-align: center; margin-top: 0.3em;">
                    Backbone layers identical (frozen) — invariance emerges in learnable projection head
                </p>
            </section>

            <!-- RQ4: What causes invariance? -->
            <section>
                <h2>RQ4: What Components Cause Invariance?</h2>
                <div class="card-green card" style="font-size: 1.1em; margin-bottom: 0.5em;">
                    <strong>✓ Pooling weights + projection head.</strong> CKA shows layer 11 diverges (0.098)
                </div>
                <div class="two-col" style="gap: 1em;">
                    <div class="figure-container">
                        <img src="../../figures/rq4/cka_layer_divergence.png" alt="CKA Layer Divergence" style="max-height: 280px;">
                        <div class="figure-caption">CKA similarity per layer</div>
                    </div>
                    <div class="figure-container">
                        <img src="../../figures/rq4/intervention_comparison.png" alt="Intervention Comparison" style="max-height: 280px;">
                        <div class="figure-caption">Ablation: component patching</div>
                    </div>
                </div>
            </section>

            <!-- RQ4: Representation Visualization -->
            <section>
                <h2>RQ4: Representation Visualization</h2>
                <div class="figure-container">
                    <img src="../../figures/rq4/representation_dr.png" alt="Representation DR" style="max-height: 380px;">
                    <div class="figure-caption">PCA / UMAP / t-SNE of learned representations (ERM vs DANN)</div>
                </div>
                <div class="two-col" style="margin-top: 0.5em; font-size: 0.9em;">
                    <div class="card">
                        <strong>ERM:</strong> Codec-separated clusters
                    </div>
                    <div class="card-green card">
                        <strong>DANN:</strong> Mixed/overlapping representations
                    </div>
                </div>
            </section>

            <!-- Key Ablation: ERM+Aug -->
            <section>
                <h2>Key Ablation: Augmentation ≠ DANN</h2>
                <div class="rq-box">
                    Does codec augmentation alone improve OOD generalization?
                </div>
                <table class="data" style="margin-top: 1em;">
                    <tr>
                        <th>Model</th>
                        <th>Backbone</th>
                        <th>Eval EER</th>
                        <th>vs ERM</th>
                    </tr>
                    <tr>
                        <td>ERM</td>
                        <td>WavLM</td>
                        <td>8.47%</td>
                        <td>—</td>
                    </tr>
                    <tr>
                        <td>ERM+Aug</td>
                        <td>WavLM</td>
                        <td>8.47%</td>
                        <td><span class="tag tag-amber">Identical</span></td>
                    </tr>
                    <tr class="highlight">
                        <td>DANN</td>
                        <td>WavLM</td>
                        <td>7.34%</td>
                        <td><span class="tag tag-green">−13%</span></td>
                    </tr>
                    <tr>
                        <td>ERM</td>
                        <td>W2V2</td>
                        <td>15.30%</td>
                        <td>—</td>
                    </tr>
                    <tr>
                        <td>ERM+Aug</td>
                        <td>W2V2</td>
                        <td>15.79%</td>
                        <td><span class="tag tag-red">Worse</span></td>
                    </tr>
                </table>
                <div class="card-accent card" style="margin-top: 0.8em;">
                    <strong>Conclusion:</strong> Augmentation alone is insufficient — DANN's adversarial objective is necessary
                </div>
            </section>

            <!-- Baselines -->
            <section>
                <h2>Baseline Comparison</h2>
                <table class="data">
                    <tr>
                        <th>Model</th>
                        <th>Type</th>
                        <th>Eval EER</th>
                    </tr>
                    <tr class="highlight">
                        <td><strong>WavLM DANN</strong></td>
                        <td>SSL + DANN</td>
                        <td><strong>7.34%</strong></td>
                    </tr>
                    <tr>
                        <td>WavLM ERM</td>
                        <td>SSL baseline</td>
                        <td>8.47%</td>
                    </tr>
                    <tr>
                        <td>W2V2 DANN</td>
                        <td>SSL + DANN</td>
                        <td>14.33%</td>
                    </tr>
                    <tr>
                        <td>TRILLsson Logistic</td>
                        <td>Non-semantic</td>
                        <td>23.75%</td>
                    </tr>
                    <tr>
                        <td>TRILLsson MLP</td>
                        <td>Non-semantic</td>
                        <td>25.65%</td>
                    </tr>
                    <tr>
                        <td>LFCC-GMM</td>
                        <td>Classical</td>
                        <td>43.33%</td>
                    </tr>
                </table>
                <p class="small" style="margin-top: 0.8em; text-align: center;">
                    SSL backbones significantly outperform non-semantic and classical approaches.<br>
                    DANN provides additional improvement on top of strong SSL baseline.
                </p>
            </section>

            <!-- Novelty -->
            <section>
                <h2>Novelty & Contributions</h2>
                <div class="rq-box" style="font-size: 0.95em;">
                    "First systematic application of domain-adversarial training (DANN) specifically for codec robustness in speech deepfake detection."
                </div>
                <div style="margin-top: 1em;">
                    <ul class="checklist">
                        <li class="done">DANN applied specifically to codec mismatch problem</li>
                        <li class="done">Frozen backbone + DANN = invariance in projection layer only</li>
                        <li class="done">Probing + CKA analysis provides interpretability</li>
                        <li class="done">Ablation confirms augmentation ≠ adversarial training</li>
                    </ul>
                </div>
                <div class="card" style="margin-top: 1em;">
                    <strong>Practical takeaway:</strong> Domain invariance doesn't require fine-tuning billion-parameter models — a lightweight projection head is sufficient
                </div>
            </section>

            <!-- Limitations -->
            <section>
                <h2>Limitations</h2>
                <div class="two-col">
                    <div>
                        <ul style="font-size: 0.9em;">
                            <li><strong>2 synthetic codecs</strong> (MP3, AAC)<br>
                                <span class="small">OPUS failed silently during training</span></li>
                            <li><strong>Backbone matters more</strong><br>
                                <span class="small">WavLM (7.34%) >> W2V2 (14.33%)</span></li>
                            <li><strong>Frozen backbone</strong><br>
                                <span class="small">Limits where invariance can emerge</span></li>
                        </ul>
                    </div>
                    <div>
                        <ul style="font-size: 0.9em;">
                            <li><strong>No MMD/CORAL comparison</strong><br>
                                <span class="small">Other DA methods not evaluated</span></li>
                            <li><strong>Single training seed</strong><br>
                                <span class="small">Bootstrap CIs on eval only</span></li>
                            <li><strong>Not mechanistic interp</strong><br>
                                <span class="small">We know where, not how</span></li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Future Work -->
            <section>
                <h2>Future Work</h2>
                <ul>
                    <li><strong>Partial backbone unfreezing</strong><br>
                        <span class="small">Allow DANN to affect deeper layers</span></li>
                    <li><strong>More codec diversity</strong><br>
                        <span class="small">Neural codecs (Encodec), device/channel effects</span></li>
                    <li><strong>Compare with MMD, CORAL</strong><br>
                        <span class="small">Other domain adaptation methods</span></li>
                    <li><strong>Multi-seed experiments</strong><br>
                        <span class="small">Capture training variance</span></li>
                    <li><strong>Publication</strong><br>
                        <span class="small">Interspeech 2026 / ICASSP 2027</span></li>
                </ul>
            </section>

            <!-- Summary -->
            <section>
                <h2>Summary</h2>
                <div style="margin-top: 0.5em;">
                    <div class="card-green card">
                        <strong>RQ1:</strong> DANN reduces OOD gap by 66% (160% → 54%)
                    </div>
                    <div class="card-green card">
                        <strong>RQ2:</strong> Improvement across all codecs
                    </div>
                    <div class="card-green card">
                        <strong>RQ3:</strong> Invariance emerges in projection layer
                    </div>
                    <div class="card-green card">
                        <strong>RQ4:</strong> Pooling weights + projection head are key
                    </div>
                </div>
                <div style="margin-top: 1em; text-align: center;">
                    <div class="metric-box green">
                        <span class="value">7.34%</span>
                        <span class="label">Best EER</span>
                    </div>
                    <div class="metric-box blue">
                        <span class="value">0.585</span>
                        <span class="label">Best minDCF</span>
                    </div>
                    <div class="metric-box amber">
                        <span class="value">66%</span>
                        <span class="label">OOD Reduction</span>
                    </div>
                </div>
            </section>

            <!-- Thank You -->
            <section style="display: flex; flex-direction: column; justify-content: center; height: 100%;">
                <h1>Thank You</h1>
                <h3 style="font-weight: 400; margin-top: 0.5em;">Questions?</h3>
                <p style="margin-top: 2em; color: var(--text-secondary);">
                    Mike Cooper<br>
                    <span class="small">mike.cooper@student.uva.nl</span>
                </p>
                <p style="margin-top: 1.5em;">
                    <span class="small">
                        Code: <a href="https://github.com/Jmqcooper1/asvspoof5-domain-invariant-cm">github.com/Jmqcooper1/asvspoof5-domain-invariant-cm</a>
                    </span>
                </p>
            </section>

        </div>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/reveal.js@4.5.0/dist/reveal.js"></script>
    <script>
        Reveal.initialize({
            hash: true,
            slideNumber: 'c/t',
            transition: 'none',
            width: 1100,
            height: 680,
            margin: 0.08,
            center: false
        });
    </script>
</body>
</html>
